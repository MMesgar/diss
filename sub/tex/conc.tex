% for sublime text 3
%!TEX root = diss.tex

\chapter{Conclusion} 
\label{ch:conc} 
The aim of the research presented in this thesis was to provide an approach to local coherence modeling based on the connectivity structure of relations among sentences in  texts. 
To this end, we defined two major research questions: Do there exist nonlinear \textbf{connectivity patterns} in coherent texts that consider long distant relations into account? 
How can we model \textbf{sentence relations in a text beyond coreference relations over named entities and based on semantic relations} between words of sentences? 
In this chapter, we revisit the research questions and summarize our contributions towards answering the questions (Section \ref{sec:conc-contributionsn}). 
Furthermore, we discuss some avenues for future work (Section \ref{sec:conc-future_work}).

\section{Contributions}
\label{sec:conc-contributions}


In this thesis, we considered two main research questions. 
We now discuss how the research presented in this thesis contributes to answering these research questions.

\paragraph{A graph-based approach to coherence pattern mining.} 
We employed the entity graph representation to encode coreferent entity relations among sentences in a text. 
Graphs enables our model to involve connections between non-adjacent sentences as well as connections between adjacent sentences. 
We formalized the concept of connectivity pattern in linguistics \cite{danes74a} by extracting all subgraphs that occur in graph representations of texts in a corpus. 
We referred to these subgraphs as coherence patterns. 
We represented the connectivity structure among nodes in a graph by a vector where each of its elements is the frequency of one of the extracted subgraphs in the graph. 
We observed some correlation between the frequencies of coherence patterns in texts and  readability ratings assigned by humans. 
We noticed that these vectors can be supplied to a machine learning method in order to rank texts with respect to their coherence. 
Finally, we learned that by enlarging coherence patterns, i.e.\ increasing the number of nodes in subgraphs, the performance of the presented model in this thesis for the readability assessment task improves. 

As another application of coherence we evaluated our coherence patterns on extractive document summarization. 
We integrated subgraphs, extracted from a set of coherent summaries, into the process of sentence selection in a summarization system. 
We observed that summaries that are generated by considering our coherence pattens are more readable, and coherent, for human judges. 
We noticed that our coherence patterns improve the performance of the summarization system with respect to BLEU metrics as well. 

\paragraph{Developing an approach to coherence modeling based on lexical relations.} 
In order to complete our approach, we proposed a new graph-based representation for texts, rather than the entity graph representation.  
This representation is based on lexical-semantic relations between words in sentences.
A pair of content words in two sentences make a connection if there exist a lexical-semantic relation between them. 
We used pre-trained word embeddings to find out if such relation exist between two words. 
Our representation connects more number of sentences than the entity graph representation. 
Therefore, graphs provided by our model are denser than entity graphs. 
We extracted all subgraphs of lexical graphs as coherence patterns. 
First, we find out that some of these patterns are similar, in terms of structure, to patterns that are extracted from entity graphs and patterns presented in \newcite{danes74}, that our lexical model is linguistically sound. 
We observed that frequencies of coherence patterns in lexical graphs are more predictive than those in entity graphs in the for the readability ranking task. 
We noticed that large coherence patterns perform superior than the small ones in on lexical graphs too. 
However, we realized that a risk of sparsity when coherence patterns become very large. 
We adapted the Keneser-Ney smoothing for this problem in graphs, which improved the performance of our model. 

\section{Future Work}
\label{sec:conc-future_work}

Based on the research presented in this thesis, several possible ways for future work exist. 
Those can be both within coherence modeling and within other natural language processing applications.  
We discuss ... possible extensions of the work presented in this thesis. 

\paragraph{Using a machine learning method for coherence pattern mining.} 
In this thesis, we used a graph-based approach, i.e.\ entity graph or lexical graph, to capture relations among sentences in a text. 
We then applied a subgraph mining method to graphs of texts in a corpus in order to obtain coherence patterns. 
We introduced two methods for subgraph extractions: one is based on exhaustive search (Chapter \ref{ch:coh-patterns}), and the other one is based on sampling (Chapter \ref{ch:lex-graph}). 
This process is independent from the machine learning method that is used to rank texts with respect to their coherence. 
Recent improvements in deep learning methods is promising to combine these two phases. 
Deep learning model such as convolutional neural networks (CNNs) \cite{} can be employed to operate on graph representations of texts to extract coherence patterns that are beneficial for the ranking task \cite{math}. 

Furthermore, in the proposed graph representation based on lexical relations among words in sentences, words are taken into account independently. 
In other words, sentences are taken as a bag of words while the structure within sentences \cite{louis12} and the order of words in sentences \cite{} provide some clues for coherence models. 
Recurrent neural networks (RNNs) models can solve this weakness. 
These models sequentially take embeddings of each word in a sentence, and return a vector for each word. 
This vector contains information in the corresponding word embeddings and other word embeddings in the sentence. 
As we discussed, a CNN can be used on the top of the RNN layer to extract patterns automatically. 

\paragraph{Analysis of coherence patterns for other NLP applications.}
In the research presented in this thesis, we evaluated our model on two readability assessment datasets and two summarization datasets. 
Our coherence model improved the performance of these systems. 
However, coherence is a key factor in other NLP applications as well. 
An example is the essay scoring task \cite{dikli06,higgins04,miltsakaki04a,}.  
The task of assigning a score to a student essay so that the score reflects the quality of the essay. 
Of course, essay quality depends on different circumstances such as grammatical mistakes, vocabularies that are used in essays, similarity between the content of essays and the given topic for the essay, and so forth. 
A solution is to involve frequencies of coherence patterns as representative features for coherence of essays in to a feature-based essay scores. 
\newcite{burstein10} applied the similar strategy by using coherence features that are introduced in the entity grid model \cite{barzilay05a}. 

Further, a similar approach can be performed on essays written by non-native speakers. 
Texts that are written by people with an identical mother tongue may reveal certain regularities in the way that sentences are connected. 
I am curious to see if the coherence patterns presented in this thesis can distinguish essays based on the mother tongue of their authors. 
An informative dataset for this task is provided by \newcite{}. 

\paragraph{Analyzing coherence patterns for other domains and languages.}
Finally, although we demonstrated the generality of our method across different English corpora, we leave open the question of extensions to other languages and domains, where the specific patterns we detected may not exist. 






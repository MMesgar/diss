% for sublime text 3
%!TEX root = diss.tex

\chapter{Conclusion} 
\label{ch:conc} 
The aim of the research presented in this thesis was to provide an approach to local coherence modeling based on the connectivity structure of relations among sentences in  texts. 
To this end, we defined two major research questions: 
\begin{itemize}
\item \textbf{Do there exist nonlinear connectivity patterns in coherent texts such that the patterns capture \mbox{long-distance} relations among sentences?} 
\item \textbf{How can we model sentence relations in a text beyond coreference relations over entities by considering semantic relations between words in sentences?} 
In this chapter, we revisit the research questions and summarize our contributions towards answering the questions (Section \ref{sec:conc-contributions}). 
Furthermore, we discuss some avenues for future work (Section \ref{sec:conc-future_work}).
\end{itemize}

\section{Contributions}
\label{sec:conc-contributions}


In this thesis, we considered two main research questions. 
We now discuss how the research presented in this thesis contributes to answering these research questions.

\paragraph{A graph-based approach to coherence pattern mining.} 
We employed the entity graph representations to encode entity coreference relations among sentences in a text. 
Graphs enable our model to involve connections between non-adjacent sentences as well as connections between adjacent sentences. 
We formalized the concept of connectivity patterns in linguistics \cite{danes74a,stoddard91} by extracting all subgraphs that occur in graph representations of texts in a corpus. 
We referred to these subgraphs as coherence patterns. 
We represented the connectivity structure among nodes in a graph by a vector where each of its elements is the frequency of one of the extracted subgraphs in the graph. 
We observed some promising correlation between the frequencies of coherence patterns in texts and  readability ratings assigned by humans. 
We noticed that these vectors can be supplied to a machine learning method in order to rank texts with respect to their coherence. 
Finally, we learned that by enlarging coherence patterns, i.e.\ increasing the number of nodes in subgraphs, the performance of the presented model in this thesis for the readability assessment task improves. 

In another experiment, we evaluated our coherence patterns on extractive document summarization. 
So, we integrated subgraphs, which are extracted from a set of coherent summaries, into the process of sentence selection in a summarization system. 
We observed that summaries that are generated by considering our coherence patterns are more readable and coherent for human judges. 
We also noticed that our coherence patterns improve the performance of the summarization system with respect to ROUGE metrics. 

\paragraph{Developing an approach to coherence modeling based on lexical relations.} 
In order to complete our approach, we proposed a new graph-based representation, which is called LexGraph, for sentence relations in texts rather than the projection graph representations proposed by the entity graph model.   
LexGraph representation is based on lexico-semantic relations between words in sentences.
A pair of content words in two sentences make a connection if there exist a lexical-semantic relation between them. 
We used pre-trained word embeddings to find out if such relations exist between two words or not.  
Our representation connects more number of sentences in comparison to the entity graph representation. 
Therefore, graphs provided by our model are denser than entity graphs. 
We extracted all subgraphs of lexical graphs as coherence patterns. 
First, we find out that some of these patterns are similar, in terms of structure, to patterns that are extracted from entity graphs and patterns presented in \newcite{danes74a}.
This shows that our LexGraph model is linguistically sound. 
We observed that frequencies of coherence patterns in lexical cohesion graphs are more predictive than those in entity graphs for the readability ranking task. 
We also noticed that large coherence patterns perform superior to the small ones on lexical cohesion graphs.  
However, there exists the risk of sparsity where coherence patterns become very large. 
We adapted the Keneser-Ney smoothing for this problem, which improved the performance of our model. 

\section{Future Work}
\label{sec:conc-future_work}

Based on the research presented in this thesis, several possible ways for future work exist. 
Those can be in directions of either the coherence modeling method or the influence of the coherence model in other natural language processing applications.   
We discuss three possible extensions of the work presented in this thesis. 

\paragraph{Using a machine learning method for coherence pattern mining.} 
In this thesis, we used a graph-based approach, i.e.\ entity graph or lexical cohesion graph, to capture relations among sentences in a text. 
We then applied a subgraph mining method to graphs of texts in a corpus in order to obtain coherence patterns. 
We introduced two methods for subgraph extractions: one is based on exhaustive search (Chapter \ref{ch:coh-patterns}), and the other one is based on sampling (Chapter \ref{ch:lex-graph}). 
This process is independent of the machine learning method that is used to rank texts with respect to their coherence. 
Recent improvements in deep learning methods is promising to combine these two phases. 
Deep learning models such as convolutional neural networks (CNNs) \cite{kimyoon14} can be employed to operate on graph representations of texts to extract coherence patterns that are especially beneficial for the ranking task. 

Furthermore, in the proposed lexical cohesion graph representation, which is based on lexical relations among words in sentences, words are taken into account individually. 
In other words, sentences are taken as a bag of words while the structure within sentences \cite{louis12} and the order of words in sentences provide some clues for coherence models. 
Recurrent neural networks (RNNs) can solve this weakness. 
These models sequentially take embeddings of each word in a sentence and at each word return a vector, which is called a state vector.  
State vectors contain information of their corresponding input word embeddings and information in embeddings of other words in a sentence as context.  
As we discussed, a CNN can be used on the top of the RNN states to extract coherence patterns automatically. 

\paragraph{Analysis of coherence patterns for other NLP applications.}
In the research presented in this thesis, we evaluated our model on two readability assessment datasets and two summarization datasets. 
Our coherence model improved the performance of these systems. 
However, coherence is a key factor in other NLP applications as well. 
An example is the essay scoring task \cite{dikli06,higgins04,miltsakaki04a,}.  
This task is about assigning a score to a student essay so that the score reflects the quality of the essay. 
Of course, the essay quality depends on more circumstances, such as grammatical mistakes, vocabularies that are used in essays, similarity between the content of essays and the given topic for the essay, and so forth. 
Therefore, in evaluation of a coherence model for this task, one should involve frequencies of coherence patterns as representative features of the coherence of an essay into a feature-based essay scorer. 
\newcite{burstein10} applied the similar strategy by using coherence features that are introduced in the entity grid model \cite{barzilay05a}. 

Further, a similar approach can be performed on essays written by non-native speakers. 
Texts that are written by people with an identical mother tongue may reveal certain regularities in the way that sentences are connected. 
We are curious to see if the coherence patterns presented in this thesis can distinguish essays based on the mother tongue of their authors. 
An applicable dataset for this task is TOEFL11 \cite{blanchard11}. 

\paragraph{Analyzing coherence patterns for other domains and languages.}
Finally, although we demonstrated the generality of our method across different English corpora, we leave open the question of extensions to other languages and domains, where the specific patterns we detected may not exist. 






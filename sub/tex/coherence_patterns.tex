% for sublime text 3
%!TEX root = diss.tex

\chapter{Graph-based Coherence Patterns}
\label{ch:coh-patterns}

In this chapter we motivate and devise a method for extracting coherence patterns.  
We first provide motivations for representing texts by graphs and for a need of graph-based patterns for coherence modeling (Section \ref{sec:motivation}).  
We then present an algorithm for coherence pattern extraction based on subgraph mining algorithms (Section \ref{sec:pattern-extraction}) in graph theory.  
We finally show how extracted coherence patterns can be used to represent the coherence of a text (Section \ref{sec:coh-modeling}), and evaluate both coherence patterns and the coherence model on assessing the readability of texts and on generating coherent summaries (Section \ref{sec:exp}). 
We conclude by a summary of main contributions presented in this chapter (Section \ref{sec:summary}). 

\section{Why Graph-based Patterns?}
\label{sec:motivation}

In Chapter \ref{ch:coherence}, we introduced the formal definition of the coherence modeling problem that is investigated in the research presented in this thesis. 
We used the set notation in mathematics to provide a general formulation. 
We first defined the relation set whose members indicate which sentences in a text are connected to each other. 
Then the concept of coherence pattern is explained as a subset of the relation set (see Definition \ref{def:def-coh-pattern} in Chapter \ref{ch:coherence}). 
Our definitions do not provide any assumption about the structure of connections among sentences in a text in order to give coherence models some flexibility to define or learn such structures. 

In Chapter \ref{ch:rel-work}, we discuss the entity grid 
\cite{barzilay05a,barzilay08} and the entity graph 
\cite{guinaudeau13} coherence models. 
The entity gird model represents the relation set in our definition by a matrix. 
This model makes the definition of coherence patterns more specific by considering sequences of grammatical transitions instead of sets.  
It pre-defines coherence pattens as all possible grammatical transitions of entities across two adjacent sentences. 
The entity graph model employs graphs to represent the relation set of a text.  
It does not extract any pattern but it makes a strong assumption about the set of all relations, which are represented by a graph, in a text:
bigger the relation set among sentences is, more coherent the text is. 

However, the entity graph model, without using any pattern, outperforms the entity grid model in experiments performed by \newcite{guinaudeau13}. 
They argue that the entity graph model achieves a higher performance than the entity grid model because the graph representation captures the distribution of entities across adjacent and non-adjacent sentences. 
Graphs are preferred more than grids for coherence modeling for two reasons:

\begin{itemize}

	\item They can model long-distant connections between sentences,

	\item They do not encounter with the sparsity problem in the text representation. 

\end{itemize}

The graph representation of the distribution of entities in a text is transformed into a one-mode projection graph among sentence nodes. 
The average outdegree of nodes in projection graphs is used to measure the extend to what sentence nodes in a projection graph are connected to each other. 
\newcite{guinaudeau13} assume that the average outdegree of a projection graph quantifies the local coherence of its corresponding text. 
This assumption has been challenged by other research (See Chapter \ref{ch:rel-work}) by defining different graph-based metrics to capture more information about the connectivity structure of graphs. 
So the average outdegree of sentence nodes in a projection graph seems insufficient to measure the connectivity style of relations among nodes in the graph and, therefor, the perceived coherence of a text. 
The results of some experiments in this chapter support this claim as well. 

This weakness of the entity graph model motives us to introduce some graph-based features that capture the connectivity style of nodes, how nodes are connected, in projection graphs. 
Considering linguistics of coherence, which are explained in Chapter \ref{ch:coherence}, we hypothesize that  coherent texts reveal similar connectivity patterns in their graph representations which make them distinguishable from graph representations of incoherent texts. 
The results of experiments in this chapter support this hypothesis (see Section \ref{sec:exp}). 

In general, the term ``pattern'' refers to some elements which are repeated or which are potentially repeatable \cite{}. 
From the machine learning perspective, ``pattern'' refers to regularities in data \cite{bishop06}.     
In graph theory patterns are subgraphs that occur or can potentially occur in graphs \cite{newmanmark10}. 
Graph-based patterns can be extracted by means of subgraph mining methods. 
Inspired by linguistic work by \newcite{danes74a}, in the research of this thesis we refer to the  subgraphs that are extracted from graph representation of texts as connectivity patterns for graphs and coherence patterns for texts.  


\section{Coherence Pattern Extraction}
\label{sec:pattern-extraction}

In Chapter \ref{ch:coherence}, different linguistic approaches to coherence patterns are discussed. 
The major intuition of coherence patterns in the research in this thesis is inspired by the theory proposed by \newcite{danes74a}. 
What \newcite{danes74a} propose is that the generalized structure of coherent texts may be described in terms of an underlying patterns of transitions between presented information in texts.  
As before we take entities mentioned in a text as pieces of information that make sentences connected. 
The entity graph representation, introduced in Chapter \ref{ch:rel-work}, is employed to model the distribution of entities across sentences of a text. 
Then the projection graphs are obtained from the entity graph representations of texts. 
Projection graphs model the structure of sentence relations, which are obtained based on the coreferent mentions, in texts. 
We employ a subgraph mining algorithm to automatically extract all connectivity patterns occurring in projection graphs of texts in a corpus as coherence patterns.   

% However, we show that there is a similarity between the automatically mined subgraphs of projection graphs and the coherence patterns proposed by \newcite{danes74a}, indicating that our model's foundation is also linguistically sound.  
% The entity graph model uses the average ourdegree to encode the connectivity of sentence nodes in projection graphs. 
% The idea is to check how well the average outdegree metric models the coherence of a set of well-written articles such as published news articles in Wall Street Journal corpus.  
% In spite of this fact that these articles are written by professional authors, human judges assigned to them different range of readability scores (More details in Section \ref{}).  
% We compute the Pearson correlation between the average outdegree of projection graph representations of news articles and their associated score assigned by human judges. 
% We define the frequency of these systematic extracted subgraphs (or coherence patterns) as features that capture the connectivity style of nodes in a projection graph and therefore the coherence property of the corresponding text.  
% We evaluate if our novel coherence features outperform the average outdegree feature in a classification task in that more coherent texts should be recognized from less coherent texts. 
% In next section, we explain how we exactly model coherence patterns. 

\subsection{Background of Graphs}
\label{sec:back-graphs}
The main goal of the research in this thesis is to employ graph representations of texts and then use the connectivity measures of graphs to quantify the coherence of texts. 
In order to explain our graph-based method, we need to define some necessary concepts from the graph literature. 
We follow \newcite{newmanmark10} to define these terms. 
We refer to them in the rest of the content of this thesis. 

\paragraph{Graph.}
%
A \emph{graph} consists of a set of vertices that are referred to as nodes and a set links that are called edges. 
Following is a formal definition of a graph. 

\begin{definition}
A graph is a pair of two finite sets $G=( V, E )$ where $V$ is a set of nodes and $E$ is a set of edges whose elements are pairs of nodes. 
\end{definition} 

\begin{figure}[!ht]
	\begin{center}
		\begin{tabular}{cc}
			\begin{tikzpicture}[shorten >=1pt,-,scale=0.5]  
				\tikzstyle{node}=[circle,thick,draw=black!90,fill=black!10,minimum size=2mm]
				\tikzstyle{edge}=[draw=black!90, thick]
			   
				 \node [node] (a) at (0,4) {\small{$a$}};
				 \node [node] (b) at (4,4) {\small{$b$}};
				 \node [node] (d) at (0,0) {\small{$d$}}; 
				 \node [node] (c) at (4,0) {\small{$c$}}; 
				 
				 \path[edge] (a) -- (b);
				 %\path[edge] (b) -- (c);
				 \path[edge] (c) -- (d);
				 \path[edge] (d) -- (a);
				 \path[edge] (a) -- (c);
			\end{tikzpicture}
			&
			\begin{tikzpicture}[shorten >=1pt,-,scale=0.5]  
				 \node (a) at (0,4) {\small{$V = \left \{ a,b,c,d \right \}$}};
				 \node (b) at (2.6,0) {\small{$E = \left \{(a,b),(a,c),(c,d),(a,d) \right \} $}};
			\end{tikzpicture}
			\\
			$G$ & $V:Nodes$, $E:Edges$ 
		\end{tabular}
	\end{center}
	\caption{$G = (V,E)$ is a graph with node set $V$ and edge set $E$.}
	\label{fig:graph}
\end{figure} 

\paragraph{Directed graphs.}
%
If nodes in a graph are ordered or relations between nodes are not symmetric then pairs in the edge set  of the graph should be interpreted as directed edges. 
A graph whose edges are directed is called a directed graph. 
Figure \ref{fig:dir_graph} shows the directed version of graph $G$ depicted in Figure \ref{fig:graph}, where edge pairs in set $E$ represent directed edges.

\begin{definition}
In a directed graph, an edge $e = (x,y)$ indicates a directed edge from node $x$ towards node $y$, which are respectively called the source node and the target node of edge $e$. 
\end{definition}

\begin{figure}[!ht]
	\begin{center}
		\begin{tikzpicture}[shorten >=1pt, -, scale=0.5]  
			\tikzstyle{node}=[circle,thick,draw=black!90,fill=black!10,minimum size=2mm]
			\tikzstyle{edge}=[draw=black!90, thick]
		   
			 \node [node] (a) at (0,4) {\small{$a$}};
			 \node [node] (b) at (4,4) {\small{$b$}};
			 \node [node] (d) at (0,0) {\small{$d$}}; 
			 \node [node] (c) at (4,0) {\small{$c$}}; 
			 
			 \path[edge,->] (a) -- (b);
			 \path[edge,->] (c) -- (d);
			 \path[edge,->] (a) -- (d);
			 \path[edge,->] (a) -- (c);	       
		\end{tikzpicture}
	\end{center}
	\caption{The directed representation of graph $G$ in Figure \ref{fig:graph}.}
	\label{fig:dir_graph}
\end{figure} 


\paragraph{Isomorphic.}
Two graphs may have an identical connectivity style but different appearances. 
Such graphs are called isomorphic graphs in the graph theory. 
More formally, two graphs are isomorphic, if there is an isomorphism relation between the graphs. 

\begin{definition}
	An isomorphism relation between graphs $G_1$ and $G_2$ is an association between node sets of these graphs:
	\begin{equation}
	f: V \left( G_1 \right) \rightarrow V \left( G_2 \right),
	\end{equation}
	such that any two nodes $u$ and $v$ of $G_1$ are adjacent in $G_1$ if and only if $f \left( u \right)$ and $f \left( v \right)$ are adjacent in $G_2$. 
\end{definition}

In other words, two graphs $G_1$ and $G_2$ are isomorphic if they fulfill two conditions: 
(i) a one\--to\--one association exists between nodes of $G_1$ and those of $G_2$, 
(ii) two nodes of $G_2$ should be connected if and only if their associated nodes in $G_1$ are connected. 
Figure \ref{fig:isomorphic_graph} illustrates two isomorphic graphs and an isomorphic relation between them.  

\begin{figure}[!ht]
	\begin{center}
		\begin{tabular}{c@{\hskip 2.5cm}c@{\hskip 2.5cm}c}

			\begin{tikzpicture}[shorten >=1pt,-,scale=0.5]  
				\tikzstyle{node}=[circle,thick,draw=black!90,fill=black!10,minimum size=2mm]
				\tikzstyle{edge}=[draw=black!90, thick]
			   
				 \node [node] (a) at (0,4) {\small{$a$}};
				 \node [node] (b) at (4,4) {\small{$b$}};
				 \node [node] (d) at (0,0) {\small{$d$}}; 
				 \node [node] (c) at (4,0) {\small{$c$}}; 
				 
				 \path[edge,->] (a) -- (b);
				 %\path[edge,->] (b) -- (c);
				 \path[edge,->] (a) -- (c);
				 \path[edge,->] (c) -- (d);
				 \path[edge,->] (a) -- (d);
		       
			\end{tikzpicture}

			 &

		  	\begin{tikzpicture}[shorten >=1pt,-,scale=0.5]  
			\tikzstyle{node}=[circle,thick,draw=black!90,fill=black!10,minimum size=2mm]
			\tikzstyle{edge}=[draw=black!90, thick]
		   
			 \node [node] (1) at (0,4) {\small{$1$}};
			 \node [node] (2) at (4,4) {\small{$2$}};
			 \node [node] (3) at (4,0) {\small{$4$}}; 
			 \node [node] (4) at (0,0) {\small{$3$}}; 
			 
			 \path[edge,->] (1) -- (2);
			 \path[edge,->] (1) -- (3);
			 \path[edge,->] (1) -- (4);
			 \path[edge,->] (2) -- (4);
		   
		  \end{tikzpicture}

			 &

		  	\begin{tikzpicture}[shorten >=1pt,-,scale=0.5]  

			 \node  (1) at (0,4) {$f(1) = a$};
			 \node  (2) at (0,2.7) {$f(2) = c$};
			 \node  (3) at (0,1.3) {$f(3) = b$}; 
			 \node  (4) at (0,0) {$f(4) = d$}; 

		  \end{tikzpicture}
		  \\ $G_1$  &$G_2$ &  $\textit{Node associations}$

		\end{tabular}
	\end{center}
	\caption{Two isomorphic graphs and a sample association between their nodes.}
	\label{fig:isomorphic_graph}
\end{figure} 


\paragraph{Subgraph.} 

Graphs are a pair of two sets: a set of nodes and a set of edges. 
Since each of these sets has several subsets, a graph has several subgraphs as well. 
Following is a formal definition of subgraphs. 

\begin{definition}
	Graph $G_2$ is a subgraph of graph $G_1$ if $G_2$ is isomorphic to a graph whose nodes and edges are a subset of nodes and edges of $G_1$.
\end{definition} 

For example consider graphs $G_1$ and $G_2$ in Figure \ref{fig:subgraph}. 
Graph $G_2$ is isomorphic with graph 
$G = \left( \left\{ a,b,c \right\}, \left\{ \left( a , b \right),\left( b , c \right) \right\} \right)$
whose node set and edge set are subsets of the node set and the edge set of $G_1$.

\begin{figure}[!ht]
	\begin{center}
		\begin{tabular}{c@{\hskip 2.5cm}c@{\hskip 2.5cm}c}
			\begin{tikzpicture}[shorten >=1pt,-,scale=0.5]  
				\tikzstyle{node}=[circle,thick,draw=black!90,fill=black!10,minimum size=2mm]
				\tikzstyle{edge}=[draw=black!90, thick]
			   
				 \node [node] (a) at (0,4) {\small{$a$}};
				 \node [node] (b) at (4,4) {\small{$b$}};
				 \node [node] (d) at (0,0) {\small{$d$}}; 
				 \node [node] (c) at (4,0) {\small{$c$}}; 
				 
				 \path[edge,->] (a) -- (b);
				 %\path[edge,->] (b) -- (c);
				 \path[edge,->] (a) -- (c);
				 \path[edge,->] (c) -- (d);
				 \path[edge,->] (a) -- (d);
			\end{tikzpicture}
			&
		  	\begin{tikzpicture}[shorten >=1pt,-,scale=0.5]  
				\tikzstyle{node}=[circle,thick,draw=black!90,fill=black!10,minimum size=2mm]
				\tikzstyle{edge}=[draw=black!90, thick]
			   
				 \node [node] (1) at (0,4) {\small{$1$}};
				 \node [node] (2) at (4,4) {\small{$2$}};
				 \node [node] (3) at (4,0) {\small{$3$}}; 
				 
				 \path[edge,->] (1) -- (2);
				 \path[edge,->] (1) -- (3);
		  	\end{tikzpicture}
		  	&
  			\begin{tikzpicture}[shorten >=1pt,-,scale=0.5]  
				\node  (1) at (0,4) {$f \left( 1 \right) = a$};
	 			\node  (2) at (0,2.7) {$f \left( 2 \right) = b$};
				\node  (3) at (0,1.3) {$f \left( 3 \right) = c$};
			\end{tikzpicture}
			\\
			$G_1$ & $G_2$  & $\textit{Node associations}$

		\end{tabular}
	\end{center}
	\caption{Graph $G_2$ is a subgraph of graph $G_1$.}
	\label{fig:subgraph}
\end{figure} 


\paragraph{K-node subgraph.}
The size of a (sub)graph is equal to the size of its node set. 

\begin{definition}
Graph $G_2 = \left( V_2 , E_2 \right)$ is a k-node subgraph of graph $G_1 = \left( V_1, E_1 \right)$ if $G_2$ is a subgraph of $G_1$, and $V_2$ has $k$ elements, $|V_2|=k$. 
\end{definition}

In Figure \ref{fig:subgraph}, graph $G_2$ is a 3-node subgraph of graph $G_1$. 

\paragraph{Induced subgraph.} 
An induced subgraph of a graph is a subgraph of the graph with an extra condition on the edges.  
This condition restricts the edge set of the subgraph so that it contains all possible edges that are present in the main graph.

\begin{definition} 
Graph $G_2 = (V_2, E_2)$ is an induced subgraph of graph $G_1 = (V_2, E_2)$ if $V_2 \subseteq V_1$ and 
$E_2 = \left\{ (x,y)| x \in V_2, y \in V_2, (x,y) \in E_1   \right\}$.
\end{definition}

Figure \ref{fig:induced_subgraphs} shows graph $G_1$ and two of its subgraphs $G_2$ and $G_3$.  
Graph $G_2$ is not an induced subgraph of graph $G_1$ because there is no edge between node $1$ and node $3$ in $G_2$ while their associated nodes, $a$ and $b$, in graph $G_1$ are connected. 
In contrast, graph $G_3$ is an induced subgraph of $G_1$ because it contains all possible edges that are present in $G_1$ and connect the nodes that are associated with nodes in $G_3$.  

\begin{figure}[!ht]
	\begin{center}
		\begin{tabular}{c@{\hskip 1.5cm}c@{\hskip 1.5cm}c@{\hskip 1.5cm}c}
			\begin{tikzpicture}[shorten >=1pt,-,scale=0.5]  
				
				\tikzstyle{node}=[circle,thick,draw=black!90,fill=black!10,minimum size=2mm]
				\tikzstyle{edge}=[draw=black!90, thick]
			   
				\node [node] (a) at (0,4) {\small{$a$}};
				\node [node] (b) at (4,4) {\small{$b$}};
				\node [node] (d) at (0,0) {\small{$d$}}; 
				\node [node] (c) at (4,0) {\small{$c$}}; 
				 
				\path[edge,->] (a) -- (b);
				\path[edge,->] (a) -- (c);
				\path[edge,->] (c) -- (d);
				\path[edge,->] (a) -- (d);

			\end{tikzpicture}
	 		&
  			\begin{tikzpicture}[shorten >=1pt,-,scale=0.5]  
	
				\tikzstyle{node}=[circle,thick,draw=black!90,fill=black!10,minimum size=2mm]
				\tikzstyle{edge}=[draw=black!90, thick]
   
	 			\node [node] (1) at (0,4) {\small{$1$}};
	 			\node [node] (2) at (4,0) {\small{$2$}};
	 			\node [node] (3) at (0,0) {\small{$3$}}; 
	 
	 			\path[edge,->] (1) -- (2);
	 			\path[edge,->] (2) -- (3);
  			\end{tikzpicture}
	 		&
  			\begin{tikzpicture}[shorten >=1pt,-,scale=0.5]  
	
				\tikzstyle{node}=[circle,thick,draw=black!90,fill=black!10,minimum size=2mm]
				\tikzstyle{edge}=[draw=black!90, thick]
   
				\node [node] (1) at (0,4) {\small{$1$}};
	 			\node [node] (2) at (4,0) {\small{$2$}};
	 			\node [node] (3) at (0,0) {\small{$3$}}; 
	 
	 			\path[edge,->] (1) -- (2);
	 			\path[edge,->] (2) -- (3);
	 			\path[edge,->] (1) -- (3);

  			\end{tikzpicture}
  			&
  			\begin{tikzpicture}[shorten >=1pt,-,scale=0.5]  
	 			\node  (1) at (0,4)   {$f \left( 1 \right) = a$};
	 			\node  (2) at (0,2.7) {$f \left( 2 \right) = c$};
	 			\node  (3) at (0,1.3) {$f \left( 3 \right) = d$}; 
  			\end{tikzpicture}
			\\
			$G_1$ & $G_2$ & $G_3$ & $\textit{Node associations}$

		\end{tabular}
	\end{center}
	\caption{Both graph $G_2$ and $G_3$ are subgraphs of graph $G_1$. In contrast to $G_2$, graph $G_3$ is an induced subgraph of $G_1$.} 
	\label{fig:induced_subgraphs}
\end{figure} 

It is worth mentioning that in the research of this thesis we mean induced subgraphs when using the term subgraph. 
However, in cases that the context is not clear we explicitly distinguish them. 

\paragraph{Graph signature.}
%
Given a list of graphs $ \zeta  = \left[ G_1, G_2, \cdots , G_m \right]$,  a graph signature of graph $G$ with respect to $\zeta$ is a vector of normalized frequencies of graphs in $\zeta$ in graph $G$:

\begin{equation}
	\phi \left( G \right) = \left( f_1, f_2, f_3, \cdots, f_m \right),
\end{equation}
where  $\phi \left( G \right)$ denotes the graph signature and $f_i$ is the frequency of graphs in graph $G$. 
The frequency of graph $G_i$ in graph $G$ is computed as follows:

\begin{equation}
 f_i = \frac{count(G_i, G)}{\sum_{G_j \in \zeta}{count(G_j, G)}}
\end{equation}
where $count(G_i, G$ is the function that counts the number of occurrences of $G_i$ in graph $G$. 
The reason of using normalized frequency instead of raw count is that normalized frequency cannot become biased to the number of nodes and edges in graph $G$. 
Normalized frequency of a subgraph can also be interpreted as the probability of the subgraph given graph $G$.  

\subsection{Coherence Pattern Mining}

The entity graph representation of a text encodes the distribution of entities across sentences in a text. 
One-mode projection graphs model the connectivity between sentence nodes with respect to the shared entities between sentences. 
The main contribution of the research in this chapter is to introduce a set of graph-based patterns that encode the structure of connections (i.e.\ connectivity style) of nodes in projection graphs.  
We use the frequencies of different subgraphs occurring in projection graphs to encode the connectivity style of projection graphs and ideally the coherence of texts. 

Given a corpus of text, we model connections among sentences in each text by its simple projection graph representation, $P_U$. 
Two sentence nodes are connected in such a projection graph if they share at least one entity node in common (See Chapter \ref{ch:rel-work} for more details).  
This leads us to a set of graphs, each of which represents connections among sentences in one text in a corpus.   
We refer to this set as a \emph{graph set}. 

The connectivity of each graph in a graph set can be represented by a graph signature, which encodes the connectivity style of projection graphs into a vector. 
However, for representing the connectivity style of a graph by a graph signature a list of basis graphs are required (See Section \ref{sec:back-graphs}).  
We extract all subgraphs that occur in projection graphs as basis graphs for computing graph signatures. 
These basis subgraphs can be taken as patterns that may have several instances, i.e.\ occurrences, in the graph representation of a text.  
That is the reason that these basis graphs are referred to as coherence patterns, and the frequencies of them, which are encoded in the signature of the graph, is considered coherence features. 
Figure \ref{fig:pattern-extraction} illustrates our approach for extracting coherence patterns.

\begin{figure}[!ht]
	\begin{center}
		\begin{tikzpicture}
			\node[] (dataset1) at (0,10)  {\includegraphics[scale=0.20]  {../figures/text.jpeg}};
			\node[] (eg1) 	   at (0,6)   {\includegraphics[scale=0.05] {../figures/bg1.png}};
			\node[] (proj1)    at (0,2.2) {\includegraphics[scale=0.05] {../figures/proj1.png}};

			\path[->, thick] (dataset1) edge  (eg1);
			\path[->, thick] (eg1) edge  (proj1);



			\node[] (dataset2) at (3,10)  {\includegraphics[scale=0.20]{../figures/text.jpeg}};
			\node[] (eg2) 	   at (3,6)   {\includegraphics[scale=0.05]{../figures/bg1.png}};
			\node[] (proj2)    at (3,2.2) {\includegraphics[scale=0.05]{../figures/proj1.png}};
			\path[->, thick] (dataset2) edge  (eg2);
			\path[->, thick] (eg2) edge  (proj2);



			\node[] (eg) at (6,8) {...};

			\node[] (dataset3) at (9,10)  {\includegraphics[scale=0.20]{../figures/text.jpeg}};
			\node[] (eg3) 	   at (9,6)	  {\includegraphics[scale=0.05]{../figures/bg1.png}};
			\node[] (proj3)    at (9,2.2) {\includegraphics[scale=0.05]{../figures/proj1.png}};
			\path[->, thick] (dataset3) edge  (eg3);
			\path[->, thick] (eg3) edge  (proj3);
			
			
			\node[] (minesg) at (5,-2.2) {\includegraphics[scale=0.5]{../figures/3node.jpg}};
			\path[->, thick] (proj1) edge (minesg);
			\path[->, thick] (proj2) edge (minesg);
			\path[->, thick] (proj3) edge (minesg);
			
		\end{tikzpicture}
	\end{center}
	\caption{An illustration of the approach employed for extracting coherence patterns.}
	\label{fig:pattern-extraction}
\end{figure}


\paragraph{The gSpan Method.}
%
Coherence patterns are subgraphs that occur at least once in one of projection graphs of texts in a corpus. 
Mining all subgraphs that occur in a graph set is computationally expensive and is proved to be an NP-complete problem \cite{althaus04}. 
Intuitively, a graph with $|E|$ edges, potentially has $\mathcal{O} \left( 2^{| E |} \right)$ subgraphs.  
A graph with $| V |$ nodes at most has  $\frac{(| V |-1)(| V |-2)}{2}$ edges which is in order of $\mathcal{O} \left( | V | ^2 \right)$. 
So the number of subgraphs in a graph is an exponential order of the squared number of nodes in the graph. 

However, the goal of the research in this thesis is not to develop an algorithm for mining subgraphs.  
This problem has been widely studied in computer science and different algorithms and packages have also been developed for it. 
The gSpan algorithm \cite{yanxifeng02} is one of the efficient methods for mining subgraphs from graphs in a graph set. 
Here, we briefly describe the idea and the method of the gSpan algorithm.  
Interested readers may find more information about the exact algorithm of gSpan in \newcite{yanxifeng02}. 

The gSpan, which stands for \underline{g}raph-based \underline{S}ubstructure \underline{pa}tter\underline{n} mining, algorithm is an approach for extracting all connectivity patterns (i.e.\ subgraphs) that occur in a graph set. 
It discovers all subgraphs without generating the candidates, so
it is efficient in terms of both computation time and memory usage. 
The gSpan method orders graphs in a graph set with respect to their structures and then adapts a Depth-First-Search (DFS)  strategy to extract connected subgraphs efficiently. 
It begins with subgraphs with only two nodes and expands it to larger subgraphs. 


\section{Coherence Modeling}
\label{sec:coh-modeling}

Here we explain how coherence patterns can be used to measure the coherence of a text. 
Given a corpus of texts, we employ the entity graph to represent the entity distribution across sentences of each text in the corpus. 
We apply a one-mode projection on each entity graph to construct a projection graph (i.e.\ $P_U$) over the sentence nodes of the entity graph. 
The projection graph models the overall entity-based relationships among sentences of a text.  

We extract all possible k-node subgraphs (i.e.\ coherence patterns) which occur in projection graph representations of texts in the corpus. 
The parameter k controls the size of subgraphs.  
Controlling the size of subgraphs mainly helps to run the subgraph mining algorithm more efficiently in terms of the computational time.
In addition, it controls the number of possible subgraphs that can be extracted: large values of k yield many number of possible graphs with the size of k. 
Moreover, small subgraphs are likely to occur inside large subgraphs. 
Therefore involving subgraphs with different sizes result in subgraphs whose frequencies might be dependent to one another.  
This type of features are advised to be supplied separately to machine learning methods \cite{aggarwalcharu18}. 

Assume that $m$ coherence patterns are mined from all graph representations of texts in a corpus, the coherence of a text is encoded by a vector of frequencies of these patterns in the graph representation of the text. 
More formally, the coherence of  text $d$ is represented by a vector as follows:

\begin{equation}
Coh(T) \approx <f_0,f_1,f_2,...,f_m>
\end{equation}
where $f_i$ represents the frequency of the $i${th} pattern in the graph representation of text $d$. 

This vector representation of coherence is identical with the graph signature concept in graph theory (See Section \ref{sec:back-graphs}). 
As these vectors can be used to model the similarities and dissimilarities in connectivity structures of graphs, they can also model similarities and dissimilarities between coherent and incoherent texts. 

From the machine learning viewpoint, these vectors can be taken as feature vector representations of coherence. 
Each element of a vector is a feature which represents one aspect of the connectivity structure of sentences in a text. 
Consequently, these feature vectors can be supplied to a machine learning model in order to rank texts with respect to their coherence. 
A machine learning model during training learns to map a feature vector to a score, which can be interpreted as a coherence score, such that the score of a more coherent text be greater than the score of a less coherent one. 
More formally, given two texts $d$ and $d^\prime$ if text $d$ is more coherent than text $d^\prime$ then a machine learning model learns parametric function $\beta$ such that 

\begin{equation}
\beta (d_v) > \beta (d^\prime_v),
\end{equation}
where $d_v$ and $d^\prime_v$ are the feature vectors representing the coherence property of these texts. 

\section{Experiments}
\label{sec:exp}

In this section we perform a set of experiments to assess coherence patterns and features discussed in this chapter. 
We fist investigate how patterns and their frequencies behave on encoding coherence in comparison to the average outdegree.  
We then examine how the size of patterns affects the predictive power of our features for distinguishing graph representations of coherent texts against incoherent ones. 

To this end, we limit the size of patterns by fixing parameter k in the model, which equals to the number of nodes in subgraphs (See Section \ref{sec:coh-modeling}). 
This yields two sets of patterns. 
One set consists of subgraphs with three nodes, 3-node patterns, and the other set contains subgraphs with four nodes, which are referred to as 4-node patterns.  
There is no criteria on the number of edges in subgraphs.  

We begin with extracting 3-node subgraphs in order to examine the soundness of mined coherence patterns.  
3-node subgraphs are the smallest meaningful patterns that can model the connectivity style of sentence nodes in projection graphs. 
There is only one 2-node subgraph, $G = \left( V = \lbrace a,b \rbrace, E=\lbrace \left( a, b \right) \rbrace \right)$, that its frequency in a projection graph is equal to the number of edges in the graph. 
It has the same interpretation as the average outdegree applied by the entity graph model.  
3-node subgraphs are too small and likely to occur in most projection graphs in a graph set. 
Moreover, in order to analyze impacts of the size of patterns, we extract 4-node subgraphs to have more informative representations of the connectivity style of graphs. 

As we discussed in Chapter \ref{ch:coherence}, coherence is better to be evaluated in an extrinsic fashion. 
It is mainly because annotating texts for coherence is quite expensive and controlling all conditions for annotators is very difficult \cite{karamanis04a}. 
In the research in this thesis we focus on two extrinsic evaluation tasks: readability assessment and automatic text summarization. 
The former one is used to evaluate the predictive power of different proposed coherence features by computing the correlation between the values of the coherence features and the readability ratings assigned by human judges. 
We also check how well coherence features can rank texts with respect to their readability level. 
The latter task is a specific instance of text generation, where a subset of informative sentences in a text should be extracted and presented in a proper order to generate a coherence and readable summary. 
In this experiment, we evaluate the capabilities of our coherence patterns in producing coherent summaries. 
We show that by integrating our coherence patterns into a graph-based text summarizer \cite{parveen15a}, the performance of the summarizer improves in terms of ROUGE metrics and human qualitative evaluations.

\subsection{Readability Assessment}
\label{sec:readability_assessment}

Readability assessment is about how well a text is understandable for its readers? 
Possible applications of readability assessment are automatic text summarization and simplification systems. 
Measuring readability can also be used in question answering and knowledge extraction systems to prune texts with low readability \cite{kate10}. 

The readability assessment task is challenging because various factors influence the processing time of a text for its readers including different text properties such as syntactic and semantic features.
Therefore, different text features can be used to assess readability including shallow features \cite{flesch48,kincaid75}, language modeling features \cite{siluo01,collins-thompson04}, syntactic features \cite{schwarm05} and the text flow or coherence \cite{barzilay08,pitler08}.
In the research of this thesis the readability assessment task basically is utilized to evaluate the impact of coherence features to quantify the difficulty of texts.  
In a coherent text each sentence has some connections with other sentences. 
Although these local connection somewhat make texts easy to read, the coherence features introduced by the entity grid model \cite{barzilay08} are not strongly correlated with readability ratings assigned by human judges \cite{pitler08}.  
It is shown that the entity graph representations of the entity distribution across sentences provide more informative representation than the entity grid model (See Chapter \ref{ch:rel-work}).  
Here, we first investigate if the average outdegree metric proposed by the entity graph model strongly correlates with readability ratings. 
We also use this experiment to evaluate and interpret our coherence patterns. 

It is worth to emphasis that the readability of a text is, of course, beyond the coherence of the text. 
This is why we do not use coherence features to exactly predict the readability scores associated with texts. 
However, because coherence is one of the crucial factors in readability assessment, easy-to-read texts imply to be  coherent as well. 
We expect that the values of coherence features show a strong correlation with readability scores associated with texts. 
In another experiment, we also check how well we can rank texts with respect to their readability if only coherence has been taken into account. 


\subsubsection{Data}
\label{sec:data_pitler}
We use the dataset collected by \newcite{pitler08}. 
It consists of thirty articles randomly selected from the Wall Street Journal corpus. 
These articles are intended for an educational adult audience so they are well-written and free of grammatical error. 
The articles were rated by three human judges on a scale from $1$ to $5$ where a higher ratings indicates an easier text to read. 
Each of judges was given unlimited time to read the texts and perform the ratings. 
Human judges received following questions \cite{pitler08}:
\begin{itemize}
	\item How well-written is this article?
	\item How well does the text fit together?
	\item How easy was it to understand?
	\item How interesting is this article?
\end{itemize} 
 
\newcite{pitler08} state that since in most cases judges gave the same rating to all questions, they only consider the given rates for the first question (``How well-written is this article?''). 
Then the average ratings for this question is defined as the final rating of a text. 
This is the reason that they use these scores for coherence evaluations as well \cite{pitler08}. 
This dataset is suitable for coherence evaluation because its articles appeared in the Wall Street Journal and are aimed at the same target audience. 
Therefore, the quality of articles relates to the discourse features such as coherence rather than surface features. 
The text presented in Example \ref{ex:wsj-1818} is one\footnote{The article's ID is WSJ-1818.} of the articles in this dataset with the final human readability score 3.7 out of five.  


\begin{examples}
	\label{ex:wsj-1818}
	The Associated Press's earthquake coverage drew attention to a phenomenon that deserves some thought by public officials and other policy makers. 
	Private relief agencies, such as the Salvation Army and Red Cross, mobilized almost instantly to help people, while the Washington bureaucracy ``took hours getting into gear.'' 
	One news show we saw yesterday even displayed 25 federal officials meeting around a table. 
	We recall that the mayor of Charleston complained bitterly about the federal bureaucracy's response to Hurricane Hugo. 
	The sense grows that modern public bureaucracies simply don't perform their assigned functions well. 
\end{examples}

% \textbf[Do you have some statistics about the dataset. If so put it here. Read Pitler and Nenkova paper for one more time.].

We exclude three articles from the dataset to make the texts consistent in style; for instance one of these articles is poem that follows a totally different style. 
The final list of articles that are used from this dataset in the experiments presented in this thesis is as follows:
\emph{
WSJ\_0068,
WSJ\_0177,
WSJ\_0232,
WSJ\_0311,
WSJ\_0402,
WSJ\_0494,
WSJ\_0613,
WSJ\_0663,
WSJ\_0717,
WSJ\_0744,
WSJ\_1011,
WSJ\_1027,
WSJ\_1043,
WSJ\_1281,
WSJ\_1324,
WSJ\_1472,
WSJ\_1520,
WSJ\_1724,
WSJ\_1746,
WSJ\_1773,
WSJ\_1784,
WSJ\_1818,
WSJ\_1906,
WSJ\_2121,
WSJ\_2238,
WSJ\_2336,
} and 
\emph{
WSJ\_2339
}.

% One article is poem and is removed because we want to analyze articles with the same style. 
% Two other articles are missing in the new versions of Penn Discourse Treebank.
% The complete list of article IDs and their associated readability scores are presented in Appendix \ref{}.
% : \texttt{wsj\--0382} does not exist in the Penn Treebank \cite{marcus94}. 
% \newcite{pitler08} also remove one file from their experiments. 
% We assume that it is  \texttt{wsj\--0382}.}. 
% \texttt{wsj\--2090} does not exist in the Penn Discourse Treebank \cite{prasad08a}. 
% \texttt{wsj\--1398} is a also poem.

\subsubsection{Feature Analysis}

The goal of this experiment is to investigate the correlation of different coherence features with with readability scores that are associated  with the articles. 
To this end, we represent each article in the dataset by its entity graph, where entities are obtained heuristically by string match between all nouns in articles. 
We apply a one-mode projection to obtain projection graphs, specifically $P_U$. 
This projection graph models the entity-based connectivity between sentences of articles. 
Given the corresponding projection graphs of articles in a corpus, we compute the Pearson correlation between the value of a feature and readability scores associated with articles. 
The reason that we compute the Pearson correlation between the the value of coherence features and the readability rating is that we assume both of these values are meaningful by themselves. 
However, other correlation assessment methods such as the Spearman correlation could also be used to only check how well rankings of texts based on these values correlate with each other. 
But the Spearman's rank correlation coefficient can not be used a significant  measure of the strength of the association between variables \cite{hauke11}.

\paragraph{The Pearson correlation coefficient.} 
The Pearson correlation coefficient is a measure of the linear correlation between values of two variables. 
Here variables are a coherence feature and the readability ratings assigned to articles by humans. 
The Pearson correlation coefficient, $\rho$, ranges between $-1$ and $+1$ where a high absolute value of $\rho$ shows a strong correlation between variables. 
The sign of $\rho$ indicates the direction of relationship between examined variables. 
In extreme cases, $+1$ shows a total positive linear correlation, $0$ is no linear correlation, and $-1$ is a total negative linear correlation. 
The Pearson correlation also measures how statistically significant examined variables are correlated. 
This measure is referred to by $p\_value$. 
We consider correlations with $p\_value < 0.05$ statistically significant. 
We use the Pearson correlation coefficient to find features correlated with readability scores. 
\newcite{pitler08} employ this metric to evaluate entity transition features extracted from the entity grid representation \cite{barzilay08} of texts for the readability assessment task. 
We follow them and use this correlation coefficient metric in our evaluations. 


We compare following features with each others: average outdegree, frequencies of 3-node patterns, frequencies of 4-node patterns. 

\paragraph{Experimental settings.} 
In order to be compatible with the entity grid features that are used by \newcite{pitler08}, we use the gold parse trees in the Penn Treebank II \cite{marcus94} to extract all nouns in an article as mentions. 
All nouns with identical stems are taken coreferent to the same entity. 
The Stemmer class from Stanford CoreNLP\footnote{V3.2.0, 2013-06-19} is employed in this regard.  
The entity graph implementation is performed in Java and is publicly available in the Github of the author of this thesis
\footnote{The code of the entity graph project is here: \url{}.}. 

The subgraph mining and primary subgraph counting parts are performed by the Java implementation of the gSpan algorithm that is also publicly available\footnote{\url{http://www.cs.ucsb.edu/~xyan/software/gSpan.htm}}. 
This package counts all subgraphs regardless of this fact that a subgraph is induced or not. 
Since we are interested in only induced subgraphs we employed Sage-Math\footnote{\url{http://sagemath.org/download- linux.html}} for counting induced subgraphs in each graph.  
For computing the correlation between feature values and readability scores we use the Pearson correlation, which is implemented as a built-in function in R\footnote{Version: V3.2.0}. 

\paragraph{Mined Coherence Patterns.} 
Figure \ref{fig:3node-patterns} shows 3-node patterns that are extracted from projection graph representations of texts in the examined readability dataset. 
There is an order between nodes $s_t < s_u < s_v$ where ``$<$'' is the sign of preceding; sentence $s_t$ appears before both $s_u$ and $s_v$ in the input text, and sentence $s_u$ comes before $s_v$. 

\begin{figure}[!ht]

	\begin{center}

		\resizebox{\columnwidth}{!}
		{%
			\begin{tabular}{@{}c@{\hskip 1.5cm}c@{\hskip 1.5cm}c@{\hskip 1.5cm}c@{}}
				\begin{tikzpicture}  
		        	\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=5mm]
		        	\tikzstyle{edge}=[draw, thick]
		       		\begin{scope}
		         		\node [sentence] (s1) at (0,2) {$s_t$};
				        \node [sentence] (s2) at (2,2) {$s_u$};
				        \node [sentence] (s3) at (1,0) {$s_v$}; 
				        
				        \path[edge,->] (s1) edge  (s2);
				        \path[edge,->] (s1) edge  (s3);
		        	\end{scope}        
		      	\end{tikzpicture}
				&
		 		\begin{tikzpicture} 
		        	\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=5mm]
		        	\tikzstyle{edge}=[draw, thick]
		       		\begin{scope}
		         		\node [sentence] (s1) at (0,2) {$s_t$};
		         		\node [sentence] (s2) at (2,2) {$s_u$};
		         		\node [sentence] (s3) at (1,0) {$s_v$}; 
		         
		         		\path[edge,->] (s1) edge  (s3);
		         		\path[edge,->] (s2) edge (s3);
		        	\end{scope}        
		      	\end{tikzpicture}
		      	&

				\begin{tikzpicture}
		        	\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=5mm]
		        	\tikzstyle{edge}=[draw, thick]
		       		\begin{scope}
		         		\node [sentence] (s1) at (0,2) {$s_t$};
		         		\node [sentence] (s2) at (2,2) {$s_u$};
		         		\node [sentence] (s3) at (1,0) {$s_v$}; 
		         		
		         		\path[edge,->] (s1) edge (s2);
		         		\path[edge,->] (s2) edge (s3);
		        	\end{scope}        
		      	\end{tikzpicture}
		 		&
		 		\begin{tikzpicture}  
		        	\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=5mm]
		        	\tikzstyle{edge}=[draw, thick]
		       		\begin{scope}
		        		\node [sentence] (s1) at (0,2) {$s_t$};
		         		\node [sentence] (s2) at (2,2) {$s_u$};
		         		\node [sentence] (s3) at (1,0) {$s_v$};
		         
		         		\path[edge,->] (s1) edge (s2);
		         		\path[edge,->] (s1) edge (s3);
		         		\path[edge,->] (s2) edge (s3);
		        	\end{scope}        
		      	\end{tikzpicture}
		      	\\
		      	$p_1$& $p_2$ & $p_3$ & $p_4$
		\end{tabular}
	}%
	\end{center}
	\caption{Extracted 3-node patterns from the readability dataset.}
	\label{fig:3node-patterns}
\end{figure}

We interpret these patterns as follows:

\begin{itemize}
	\item \boldmath{$p_1$}\textbf{:} 
	A sentence is connected with two of its subsequent sentences.
	More precisely, at least two entities are mentioned in one sentence, $s_t$, and the subsequent ones, $s_u$ and $s_v$,  are about these entities. 
	This pattern is almost similar to two coherence patterns that are defined by \newcite{danes74a}, i.e.\ pattern 2 and pattern 3 illustrated in Table \ref{tab:danesh_coherence_patterns} in Chapter \ref{ch:coherence}.

	\item \boldmath{$p_2$}\textbf{:} 
	The connection between two sentences is made by a sentence that comes after those sentences. 
	This patterns indicates that entities in $s_t$ and $s_u$ are connected to each other in $s_v$. 
	 

	\item \boldmath{$p_3$}\textbf{:} 
	Each sentence tends to refer to an entity in its immediately preceding sentence. 
	The absence of a connection between $s_t$ and $s_v$ indicates that the entity that connects $s_t$ and $s_u$ is different with the entity that connects $s_u$ and $s_v$. 
	This pattern roughly reminds us the center in the centering theory;
	It approximately corresponds to the shift of center in the centering theory. 
	It is also almost similar to the linear pattern proposed by \newcite{danes74a}, i.e.\ pattern 1 depicted in Table \ref{tab:danesh_coherence_patterns} in Chapter \ref{ch:coherence}. 

	\item \boldmath{$p_4$}\textbf{:} 
	This pattern encodes three sentences that all are connected with each other. 
	Entities that connect sentences are not necessarily unique. 
	An important property of this pattern is that it has maximum number of edges showing many repetitions of entities among sentences. 
\end{itemize}


Figure \ref{fig:4node-patterns} shows all extracted subgraphs with four nodes from the projection graphs corresponding to texts in the readability dataset. 
These 4-node subgraphs have more capacity to capture connectivity information than 3-node subgraphs, because they contain more nodes and therefore more possible edges. 
However, 4-node subgraphs are less likely to occur in all projection graphs.
So their frequencies are expected to better distinguish between coherent and incoherent texts.  

\begin{figure}[!ht]
	\begin{center}
		\resizebox{\columnwidth}{10cm}
		{%
		\begin{tabular}{@{}c@{\hskip 1.5cm}c@{\hskip 1.5cm}c@{\hskip 1.5cm}c@{}}
			\begin{tikzpicture}
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=1mm]
        		\tikzstyle{edge}=[draw, thick,->]
       			\begin{scope}
			    	\node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
			        \node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
			        \node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
			        \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s2);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s4);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s4);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
			    	\path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
		        \end{scope}        
    	    \end{tikzpicture}
			&
			\begin{tikzpicture}
			    \tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
			    \tikzstyle{edge}=[draw, thick, ->]
			    \begin{scope}
					\node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
			        \node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
			        \node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
			        \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s2);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s4);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
			    \end{scope}        
			\end{tikzpicture}
			&
			\begin{tikzpicture}
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
       			\begin{scope}
			        \node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
			        \node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
			        \node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
			        \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s2);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s4);
			        \path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
        		\end{scope}        
      		\end{tikzpicture}
			&

			\begin{tikzpicture}
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
       			\begin{scope}
			        \node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
			        \node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
			        \node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
			        \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s2);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
		        \end{scope}        
	        \end{tikzpicture}
		    \\
		    \scriptsize{$p_1$} & \scriptsize{$p_2$} & \scriptsize{$p_3$} & \scriptsize{$p_4$}
		    \\
		    \begin{tikzpicture} 
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
       			\begin{scope}
			        \node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
			        \node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
			        \node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
			        \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s2);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s4);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s4);
			        \path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
        		\end{scope}        
      		\end{tikzpicture}
			&
			\begin{tikzpicture}
		        \tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
		        \tikzstyle{edge}=[draw, thick, ->]
		       \begin{scope}
			        \node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
			        \node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
			        \node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
			        \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s2);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s4);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s4);
			        \path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
       			 \end{scope}        
      		\end{tikzpicture}
			&
			\begin{tikzpicture}
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
       			\begin{scope}
        			\node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
        			\node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
        			\node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
        			\node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
        			\path[edge] (s1) edge [above] node[font=\tiny] {} (s3);
        			\path[edge] (s1) edge [above] node[font=\tiny] {} (s4);
        			\path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
        			\path[edge] (s2) edge [above] node[font=\tiny] {} (s4);
        			\path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
        		\end{scope}        
      		\end{tikzpicture}
			&
			\begin{tikzpicture} 
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
       			\begin{scope}
        			\node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
        			\node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
        			\node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
        			\node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
        			\path[edge] (s1) edge [above] node[font=\tiny] {} (s3);
        			\path[edge] (s1) edge [above] node[font=\tiny] {} (s4);
        			\path[edge] (s2) edge [above] node[font=\tiny] {} (s4);
        			\path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
        		\end{scope}        
      		\end{tikzpicture}
      		\\

		    \scriptsize{$p_5$} & \scriptsize{$p_6$} & \scriptsize{$p_7$} & \scriptsize{$p_8$}
			\\
			\begin{tikzpicture}
		    	\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
		       	\tikzstyle{edge}=[draw, thick, ->]
		       	\begin{scope}
		        	\node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
		        	\node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
		        	\node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
		        	\node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
		        	\path[edge] (s1) edge [above] node[font=\tiny] {} (s2);
		        	\path[edge] (s1) edge [above] node[font=\tiny] {} (s3);
		        	\path[edge] (s1) edge [above] node[font=\tiny] {} (s4);
		        	\path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
		        	\path[edge] (s2) edge [above] node[font=\tiny] {} (s4);
		        \end{scope}        
		    \end{tikzpicture}
			&
			\begin{tikzpicture}
		    	\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
		        \tikzstyle{edge}=[draw, thick, ->]
		        \begin{scope}
			        \node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
			        \node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
			        \node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
			        \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s2);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s4);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s4);
		        \end{scope} 
		    \end{tikzpicture}
 			&
			\begin{tikzpicture}
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
       			\begin{scope}
        			\node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
        			\node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
        			\node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
        			\node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
        			\path[edge] (s1) edge [above] node[font=\tiny] {} (s4);
        			\path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
        			\path[edge] (s2) edge [above] node[font=\tiny] {} (s4);
        			\path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
        		\end{scope}        
      		\end{tikzpicture}
      		&
			\begin{tikzpicture}
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
       			\begin{scope}
			        \node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
			        \node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
			        \node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
			        \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s2);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s4);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
		        \end{scope}
		    \end{tikzpicture}
			\\

			\scriptsize{$p_9$} & \scriptsize{$p_{10}$} & \scriptsize{$p_{11}$} & \scriptsize{$p_{12}$}
			\\
			\begin{tikzpicture}
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
       			\begin{scope}
       				\node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
        			\node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
        			\node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
        			\node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
        			\path[edge] (s1) edge [above] node[font=\tiny] {} (s2);
        			\path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
        			\path[edge] (s2) edge [above] node[font=\tiny] {} (s4);
        			\path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
        		\end{scope}        
      		\end{tikzpicture}
			&
			\begin{tikzpicture}
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
       			\begin{scope}
        			\node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
         			\node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
        			\node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
			        \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s2);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s4);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
        		\end{scope}        
      		\end{tikzpicture}
			&
			\begin{tikzpicture}
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
       			\begin{scope}
			        \node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
			        \node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
			        \node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
			        \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s2);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
        		\end{scope}        
      		\end{tikzpicture}
			&
			\begin{tikzpicture}
       			\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
       			\begin{scope}
        			\node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
        			\node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
        			\node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
        			\node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
        			\path[edge] (s1) edge [above] node[font=\tiny] {} (s2);
        			\path[edge] (s1) edge [above] node[font=\tiny] {} (s3);
        			\path[edge] (s2) edge [above] node[font=\tiny] {} (s4);
        			\path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
        		\end{scope}        
      		\end{tikzpicture}
			\\

			\scriptsize{$p_{13}$} & \scriptsize{$p_{14}$} & \scriptsize{$p_{15}$} & \scriptsize{$p_{16}$}
			\\
			\begin{tikzpicture}
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
       			\begin{scope}
			        \node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
			        \node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
			        \node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
			        \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s4);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
        		\end{scope}       
      		\end{tikzpicture}
      		&
			\begin{tikzpicture}
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
		        \begin{scope}
			        \node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
			        \node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
			        \node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
			        \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s2);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s4);
		        \end{scope}        
	        \end{tikzpicture}
			&
			\begin{tikzpicture}
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
       			\begin{scope}
         			\node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
         			\node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
        			\node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
        			\node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
        			\path[edge] (s1) edge [above] node[font=\tiny] {} (s3);
        			\path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
        			\path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
        		\end{scope}        
      		\end{tikzpicture}
			&
			\begin{tikzpicture}
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
       			\begin{scope}
			        \node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
			        \node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
			        \node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
			        \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s2);
			        \path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
			    \end{scope}        
     		\end{tikzpicture}
			\\
			\scriptsize{$p_{17}$} & \scriptsize{$p_{18}$} & \scriptsize{$p_{19}$} & \scriptsize{$p_{20}$}
			
			\\
			\begin{tikzpicture}
			    \tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
			    \tikzstyle{edge}=[draw, thick, ->]
			    \begin{scope}
			        \node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
			        \node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
			        \node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
			        \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s4);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s4);
			    \end{scope}        
			\end{tikzpicture}
			&
			\begin{tikzpicture}
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
        		\begin{scope}
        			\node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
				    \node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
				    \node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
				    \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
				    \path[edge] (s1) edge [above] node[font=\tiny] {} (s3);
				    \path[edge] (s1) edge [above] node[font=\tiny] {} (s4);
				    \path[edge] (s2) edge [above] node[font=\tiny] {} (s4);
        		\end{scope}        
      		\end{tikzpicture}
      		&
			\begin{tikzpicture}
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
       			\begin{scope}
			        \node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
			        \node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
			        \node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
			        \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s4);
			        \path[edge] (s2) edge [above] node[font=\tiny] {} (s4);
			        \path[edge] (s3) edge [above] node[font=\tiny] {} (s4);
        		\end{scope}        
      		\end{tikzpicture}
      		&
			\begin{tikzpicture}
        		\tikzstyle{sentence}=[circle,thick,draw=black!75,fill=black!10,minimum size=2mm]
        		\tikzstyle{edge}=[draw, thick, ->]
       			\begin{scope}
			        \node [sentence] (s1) at (0,2) {\tiny{$s_1$}};
			        \node [sentence] (s2) at (2,2) {\tiny{$s_2$}};
			        \node [sentence] (s3) at (2,0) {\tiny{$s_3$}};
			        \node [sentence] (s4) at (0,0) {\tiny{$s_4$}};  
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s2);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s3);
			        \path[edge] (s1) edge [above] node[font=\tiny] {} (s4);
        		\end{scope}        
      		\end{tikzpicture}
      		\\
      		\scriptsize{$p_{21}$} & \scriptsize{$p_{22}$} & \scriptsize{$p_{23}$} & \scriptsize{$p_{24}$}
		\end{tabular}
		}%
	\end{center}
	\caption{Coherence patterns with four nodes where $t<u<v<w$.}
	\label{fig:4node-patterns}
\end{figure}


\paragraph{Results.}

Given the extracted coherence patterns as basis graphs, we compute the graph signature representation of each projection graph corresponding with each text in the dataset. 
The elements of the graph signature of projection graph are frequencies of the extracted patterns in the projection graph. 
These elements together model the connectivity style of the graph. 
From texture perspective, the frequency of each subgraphs models how frequently a coherence pattern is used in a text. 

We begin with the evaluation of the average outdegree metric as proposed by the entity graph model. 
Table \ref{tab:correlation-outdegree} shows the results of computing the Pearson correlation between the average outdegree of three projection graphs defined in the entity graph model \cite{guinaudeau13}. 
Each row of the table presents the type of the projection graph that is used (see Chapter \ref{ch:rel-work}) to represent texts. 
The column with header $\rho$ contains the coefficient of the Pearson correlation and p\_value is what we use to identify significant correlations. 
The results show that the average outdegree of none of the projection graphs are significantly correlated with ratings assigned by humans. 
This confirms our intuition that the average outdegree metric is insufficient to capture the connectivity style of graphs, and therefore the coherence of a text. 

\begin{table}[!ht]
	\begin{center}
		\begin{tabular}{lcc}
			\toprule
 			Projection Type		& $\rho$ 						& p\_value\\
 			\midrule
			$P_U$ 				& $-0.013$ 						& $0.949$ \\
			$P_W$ 				& $\textcolor{white}{+}0.151$  	& $0.452$ \\
			$P_{Acc}$ 			& $\textcolor{white}{+}0.150$ 	& $0.455$ \\
			\bottomrule
		\end{tabular}
	\end{center}
	\caption{The correlation of the average outdegree metric of different projection graphs with human readability ratings.}
 	\label{tab:correlation-outdegree}
\end{table}


Table \ref{tab:correlation-3node} shows the Pearson correlation coefficient and their corresponding p\_value between the frequencies of 3-node coherence patterns (see Figure \ref{fig:3node-patterns}) and readability ratings assigned by human judges. 

\begin{table}[!ht]
	\begin{center}
		\begin{tabular}{lcc}
		\toprule
  	 	& $\rho$ 		& p\_value								    \\
  	 	\midrule
 		$p_1$ 			& $\textcolor{white}{+}0.310$ & $0.116$ 		\\
 		$p_2$ 			& $-0.325$ 				      & $0.098$ 		\\
		$\mathbf{p_3}$ 	& $\mathbf{-0.384}$ 		  & $\mathbf{0.048}$\\
 		$p_4$ 			& $\textcolor{white}{+}0.108$ & $0.592$			\\
 		\bottomrule
		\end{tabular}
	\end{center}
	\caption{The Pearson correlation coefficient and $p\_value$ between the frequency of 3-node patterns (see Figure \ref{fig:3node-patterns}) and readability ratings assigned by human judges.} 
 	\label{tab:correlation-3node}
\end{table}

The results presented in Table \ref{tab:correlation-3node} show that the frequencies of pattern $p_1$ and pattern $p_4$ are positively and the frequencies of pattern $p_2$ and pattern $p_3$ are negatively correlated. 
Among them, pattern $p_3$ is significantly correlated with human readability rankings. 
This pattern is similar to the shift in the center among sentences in a text; since we are computing the frequency of this pattern in each text, this result shows that texts with many shifts in the center are perceived more difficult to read. 
We notice that the frequency of pattern $p_1$ is positively correlated with readability rankings, not significantly though. 
This shows that this pattern occurs many times in easy to read texts.  
This pattern captures a sentence that introduces some information, which is limited in our model to entities, then  subsequent sentences are about those information, which is compatible with structure of paragraphs in news articles. 
Good writers usually initiate topics, ideas or claims and then provide clear elaboration and reasons. 
%That is, a sequence of many related words and phrases will be evoked to explain an idea provide an account of the writer's reasoning. 
Also, in the English-speaking school of essay writing and debating, there is the tendency to state the central claim of a text or a paragraph in the very first sentence, followed by supporting arguments \cite{peldszus15}. 

The frequency of pattern $p_2$ is negatively correlated with human rankings, showing that this pattern has not been observed in coherent texts as frequent as in incoherent ones. 
This matches with the linguistic phenomena saying that processing sentences that are independent and then are connected in a subsequent sentence is difficult and ambiguous for readers \cite{danes76}. 
Interestingly, the structural difference between pattern $p_2$ and pattern $p_1$ can be interpreted as the order of sentences. 
If node $s_t$ was before $s_u$ in pattern $p_2$ then this pattern would look like pattern $p_1$, which is a property of coherent texts. 
This means that these patterns can capture the order of information presented in sentences as well. 
Finally, the frequency of one of our coherence patterns, unlike the average outdegree, is significantly correlated with human readability ratings. 
The correlation coefficients, $\rho$, have more distant with zero in comparison with those of the average outdegree metric. 
This indicates the frequency of coherence patterns are more correlated with readability scores assigned by human judges. 
Coherence patterns capture the connectivity style among sentences in a text as small units and beyond the individual  sentence connectivity, which is one of the essential differences between our coherence patterns and average outdegree. 

Table \ref{tab:correlation-4node} shows the Pearson correlation coefficient and their corresponding p\_value between the frequencies of 4-node patterns and readability ratings assigned by human judges. 
Although patterns have the same number of nodes, they may contain different number of edges. 
The second column presents the number of edges in each pattern. 

\begin{table}[!ht]
	\begin{center}
		\begin{tabular}{lccc}
			\toprule
   								& Number of Edges & $\rho$ 						 	& p\_value				\\
   			\midrule
			$p_1$ 				& 6 			  & $\textcolor{white}{+}{0.103}$ 	& $0.609$					\\
			$p_2$ 				& 5 			  & $-0.212$ 					 	& $0.288$					\\
			$p_3$  				& 5				  & $-0.176$				     	& $0.380$					\\
			$p_4$  				& 4 			  & $-0.257$ 				     	& $0.196$					\\
			$p_5$ 				& 5 			  & $-0.140$ 					 	& $0.486$					\\
			$p_6$  				& 5 			  & $\textcolor{white}{+}{0.200}$  	& $0.317$					\\
			$\mathbf{p_7}$ 	& \textbf{5} 	  & $\mathbf{-0.402}$ 			 	& $\mathbf{0.038}$			\\
			$p_8$  				& 4 			  & $-0.317$ 					 	& $0.107$					\\
			$p_9$ 				& 5 			  & $\textcolor{white}{+}{0.153}$  	& $0.446$					\\
			$p_{10}$ 			& 4 			  & $-0.238$ 					 	& $0.232$					\\
			$\mathbf{p_{11}}$ 	& \textbf{4} 	  & $\mathbf{-0.509}$            	& $\mathbf{0.007}$			\\
			$\mathbf{p_{12}}$  	& \textbf{4} 	  & $\mathbf{\textcolor{white}{+}{0.449}}$ & $\mathbf{0.019}$	\\
			$p_{13}$			& 4 			  & $-0.045$ 						& $0.824$					\\
			$p_{14}$			& 4 			  & $-0.033$ 						& $0.870$					\\
			$p_{15}$			& 3				  & $-0.358$ 						& $0.067$					\\
			$p_{16}$ 			& 4 			  & $-0.068$ 						& $0.736$					\\
			$p_{17}$			& 3 			  & $-0.308$ 						& $0.118$					\\
			$\mathbf{p_{18}}$	& \textbf{3}	  & $\mathbf{-0.546}$				& $\mathbf{0.003}$			\\
			$\mathbf{p_{19}}$	& \textbf{3} 	  & $\mathbf{-0.601}$ 				& $\mathbf{0.001}$			\\
			$p_{20}$			& 3 			  & $\textcolor{white}{+}{0.094}$   & $0.641$					\\
			$p_{21}$			& 4 			  & $\textcolor{white}{+}{0.068}$	& $0.736$				    \\
			$p_{22}$			& 3				  & $-0.374$ 						& $0.055$					\\
			$p_{23}$			& 3				  & $-0.314$ 						& $0.111$					\\
			$p_{24}$ 			& 3				  & $\textcolor{white}{+}{0.100}$   & $0.620$					\\
			\bottomrule
		\end{tabular}
	\end{center}
	\caption{The number of edges in 4-node patterns, and the Pearson correlation coefficient and their corresponding $p\_value$ between the frequency of patterns and readability ratings.} 
	\label{tab:correlation-4node}
\end{table}

First, most 4-node patterns with less than four edges are negatively correlated with readability ratings, except $p_{20}$ and $p_{24}$ that are weakly correlated with readability rankings. 
Few connections between sentences make the text difficult to read.
Among all patterns that have positive correlation coefficients with readability scores, $p_{12}$ has the highest correlation coefficient. 
In contrast, the most negatively correlation coefficient is for pattern $p_{11}$. 
A comparison among these two patterns shows that they have the same number of edges but different styles of connectivity.
This confirms our intuitions: (i) The connectivity structure of projection graphs representing coherent texts are similar to each other and different with those that represent incoherent texts. 
(ii) The frequency of subgraphs can encode the connectivity structure of projection graphs and consequently coherence. 
Moreover, these patterns roughly remind us the \emph{ambiguity node}\ phenomenon introduced by \newcite{stoddard91} [p.\ 29]: 
\emph{
	``[...] in some cases, there may be more
	than one logical, possible node for a given cohesive element in a text, in which case, a reader may see the resulting ambiguity but not be able to decide between the choices''.
	}
In pattern $p_{11}$ a reader may make a decision about the center in $s_w$, while in $p_{12}$ the center of $s_w$ is the same as the center of $s_t$. 
This phenomenon can also be observed in all positively correlated patterns.  
It can be interpreted in the way that if readers have to return to one point in the text, they prefer to return to a sentence which is the core of the preceding sentences.
Finally, we conclude that all strongly negatively correlated patterns, such as pattern $p_7$, capture either connection shortage or the \textit{ambiguity node}\ phenomenon.

Considering the results related to 3-node patterns, presented in Table \ref{tab:correlation-3node}, and the results of 4-node patterns, shown in Table \ref{tab:correlation-4node}, two observations are noticeable.
First, the number of 4-node patterns that are significantly correlated with readability ratings is more than those in 3-node pattens. 
This confirms our intuition that large subgraphs capture more information about the connectivity style of projection graphs and therefore are powerful predictor of coherence.  
Second, the correlation coefficient obtained for pattern $p_{12}$, as the pattern with the strongest correlation, in 4-node patterns is greater than the correlation coefficient of pattern $p_4$, as the pattern with strongest correlation, in 3-node patterns. 
This can be because $p_{12}$ captures more circumstances about connectivity of node $s_t$. 
However, we should refrain of interpreting too much into these patterns. 

Finally, \newcite{pitler08} show that none of the entity transition features of the entity grid coherence model is strongly correlated with readability ratings of these texts. 
While these features are intended to capture entity-based coherence, entity transitions in isolation seem to be too weak to actually do so. 
In contrast to them we are able to report a statistically significant correlation between some entity-based features and human readability ratings.

We summarize our observations in this experiment as follows: 

\begin{itemize}

	\item The average outdegree metric proposed by \newcite{guinaudeau13} is not significantly correlated with human ratings assigned to texts in the examined dataset;

	\item 3-node patterns mined from projection graphs are roughly similar to patterns introduced by \newcite{danes74};

	\item The connectivity style of a projection graph can be encoded by the frequency of extracted subgraphs or coherence patterns; 

	\item The number of 4-node patterns whose frequencies are strongly correlated with readability ratings is more than 3-node patterns, showing that large pattern are better predictive for the coherence of a text.

\end{itemize}


\subsubsection{Readability Ranking}

In this experiment, we use coherence models to rank texts with respect to their readability property. 
Given that easier to read texts are more coherent than difficult texts, a coherence model should ideally be able to rank texts with respect to their readability. 
We investigate how well rankings predicted by a coherence model match with rankings that are based on the  readability ratings assigned by humans. 
The readability ranking task may in principle be more natural than readability assessment because in most NLP applications the main concern is with the relative quality of texts rather than their absolute scores. 
Following \newcite{pitler08} we rank texts in a pairwise approach with respect to their readability ratings that are assigned by humans. 
We treat this task as a classification task: Given a pair of texts, which one is easier to read or more coherent?

\paragraph{Evaluation Metric.}
The performance of a set of coherence features for the readability ranking task is measured by the accuracy of rankings  predicted by the classification model where it is supplied by the feature set. 
The accuracy is calculated as follows:

\begin{equation}
Accuracy = \frac{\textit{the number of correct rankings}}{\textit{the number of pairs}}. 
\end{equation} 

We also compute the F-measure in order to compare our features with baseline features. 
The F-measure is the average of the F1-measures that are computed for each class. 
Note that our problem is ranking that is treated as classification.  There is no true class in to be classified. 
So, in different turns we take each class as the true class and compute the F1-measure for that class. 
Then we report the average F1-scores as the F-measure for this task. 
The F1-measure for each class is the harmonic mean of precision ($P$) and recall $R$:
\begin{equation}
F-measure = 2.\frac{P \cdot R}{P + R}.  
\end{equation}
Precision is computed as follows: 

\begin{equation}
P = \frac{\textit{the number of correct decisions}}{\textit{the number of decisions}}
\end{equation}

Recall is calculated as follows:

\begin{equation}
R = \frac{\textit{the number of correct decisions}}{\textit{the number of pairs in that class}}
\end{equation}

Since the dataset is not accompanied by any standard split of training and test sets, we use 10-fold cross-validation for comparing the quality of different coherence feature sets. 
The reported accuracy is the average over all accuracies obtained from all runs of 10-fold cross-validation. 

\paragraph{Experimental settings.}
%
We follow the settings of this experiment as performed by \newcite{pitler08}. 
Text pairs include texts, from the dataset introduced in Section \ref{sec:data_pitler}, that their readability scores differ by at least $0.5$. 
This criteria ensures that the difference in readability ratings of texts in a text pair is noticeable enough that a coherence model distinguishes their difference. 
If the first text in a pair has a greater readability score, a label ``A'' is assigned to the pair, otherwise a label ``B'' is assigned. 
In total, the number of pairs obtained by this procedure is 209 pairs in which 105 pairs have label ``A''  and 104 pairs have label ``B''.  
We employ WEKA's linear support vector implementation (SMO) to classify the pairs.
The SMO model is supplied by different sets of coherence features representing the coherence of each text. 
The first set of coherence features is grammatical transitions of entities, with sequence length of two, proposed by the entity grid model \cite{barzilay05a,barzilay08}. 
For creating entity grids we use Brown Coherence Toolkit v1.0, which is set up in a docker by the author of this thesis\footnote{The docker is available \url{https://github.com/MMesgar/text_to_entity_grid}} to be used quickly for the future research. 
The input parse trees to this toolkit are gold parse trees from Penn TreeBank II \cite{marcus94}. 

\paragraph{Results.}
%
We compare our graph-based coherence features, which are the frequencies of \mbox{k-node} subgraphs in projection graphs, with the proposed features obtained from grammatical transitions of entities by the entity gird model. 
In order to compare different sets of coherence features, we employ the same machine learning model, i.e. SVM, for training and testing on each feature set. 

Table \ref{tab:ranking-pitler} summarizes the results of the readability ranking task on this dataset. 
Since the reported F-Measure and Accuracy have the same trend, we compare systems only based on Accuracy.  
Baseline features are the frequency of grammatical transitions of entities across sentences. 
This feature set is also evaluated\footnote{The accuracy reported in their paper is $79.42\%$. Our reimplementation achieves higher accuracy because our dataset has three articles less.} as coherence features on this dataset by \newcite{pitler08}.

\begin{table}[!ht]
	\begin{center}
		\begin{tabular}{lcc}
			\toprule
			Features 						  & Accuracy		& F-measure	\\
			\midrule
			None (Majority class) 			  & $47.85\%$		& $0.478$		\\
			Baseline features 			  	  & $83.25\%$     	& $0.833$		\\
			3-node 							  & $79.43\%$		& $0.794$		\\
			4-node 						      & $89.00\%$		& $0.890$		\\
			3-node \& 4-node 				  & $88.52\%$		& $0.885$		\\
			Baseline features + 4-node 				  & $93.30\%$		& $0.933$		\\
			\bottomrule
		\end{tabular}
	\end{center}
	\caption{The accuracy of the SMO classifier with different sets of coherence features.}
	\label{tab:ranking-pitler}
\end{table}

The accuracy of a the classifier where it is trained with the frequency of 3-node subgraphs as coherence features is lower than where the baseline coherence features are employed.  
This could happen because of two reasons. 
The entity grid features represent grammatical role transitions of entities, which is more informative than the connections used in 3-node patterns that only model the existence of a shared entity between sentences. 
On the other hand, 3-node patterns are small and consequently more likely to occur in most projection graphs, so their frequencies cannot distinguish between coherent and incoherent texts easily. 

The feature set containing the frequency of 4-node patterns outperforms the baseline feature set by about $6\%$. 
This confirms our intuition that the entity-based connectivity structure among sentences, which is modeled by projection graphs, distinguishes coherent texts from incoherent texts. 
An advantage of 4-node patterns over the baseline features is that long-distant relations are also taken into account. 
however, our coherence patterns lack the grammatical information in the entity relations. 
Our other hypothesis was that since 4-node patterns are larger than 3-node patterns, they have more capacity in terms of nodes and edges, to model the connectivity of nodes in projection graphs and therefore coherence. 
This hypothesis is confirmed by comparing the accuracy of 4-node patterns against 3-node patterns.
4-node patterns outperform 3-node patterns by $10\%$ difference in accuracy. 
That is a considerable improvement. 
It also verifies that large subgraphs capture more information about the connectivity style of nodes in projection graphs.    

We combine the frequency of all 3-node and 4-node patterns into one feature set, and supply it to the classifier.   
The obtained accuracy is superior than the one with only 3-node patters but slightly worse  ($-1\%$) than the one with only 4-node patterns. 
An explanation for this is that 4-node patterns implicitly contain 3-node patterns in themselves. 
Combining these two sets of features does not probably provide any useful information for modeling the connectivity style of projection graphs more than what exists in 4-node patterns. 

Finally, the combination of baseline coherence features, i.e.\ the frequency of grammatical transitions of entities over adjacent sentences, and 4-node subgraphs achieves the best accuracy. 
An interpretation for this is that although our coherence patterns capture the connectivity structure among sentences of a text, integrating linguistic information such syntactic transitions of entities may improve the quality of a coherence model.  

\subsection{Automatic Summarization}
\label{sec:auto-summarization}
In this section we evaluate our approach to coherence patterns in automatic text summarization, which an instance of text generation systems. 
We employ the summarization proposed by \newcite{parveen15a} as it is based on the entity graph model (see Chapter \ref{ch:rel-work}). 
This matters because the entity graph model is the framework of our coherence model as well.  
\newcite{parveen15a} assume that the outdegree of a node in the projection graph of an input text measures how crucial the corresponding sentence is for the coherence of the summary.  
This assumption has three weaknesses: 

\begin{itemize}
	\item 
	The summarizer becomes bias to extract sentences at the beginning of a text because these sentences potentially have high outdegrees. 
	This is because edges in a projection graph are directed to capture the sentence order in a text.
	As the text progresses, the potential outdegrees of sentence nodes decrease. 
	As an example, assume a text with $n$ sentences, the outdegree of the first sentence in this text can be high as up to $n-1$ but the outdegree of the last sentence is zero. 
	It is worth mentioning that in the entity graph coherence model, the outdegrees of nodes in a projection graph are averaged to measure the connectivity of the graph or the coherence of the entire text.  
	Limiting this metric to each sentence node does not imply that the sentence is crucial for the coherence of the summary of the text.   
	
	\item 
	In the summarization model proposed by \newcite{parveen15a}  the outdegrees of sentence nodes are computed in the projection graph of the input text.   
	The ideal aim of a summarization system is to extract sentences that make the summary coherence. 
	So, the connectivity of sentences should be evaluated with respect to only other selected sentences for the summary, rather than based on the sentences in the input text. 


	\item In the readability experiment we have shown that the average outdegree is not the best metric for encoding the connectivity style of projection graphs and therefore coherence. 
	
\end{itemize} 

We focus on the coherence aspect of the summarization system proposed by \newcite{parveen15a} with two motivations: using the automatic summarization task as another application for evaluating our graph-based coherence patterns; and improving the performance of the examined summarization  model by integrating our coherence patterns, rather than outdegree, into the summarization model. 
Our intuition is that human generated summaries given in a dataset are expected to be coherent enough to be readable.
So if a summarization system extracts sentences of a text so that their connectivity style in the produced summary is similar to connectivity styles of sentences in human generated summaries then the produced summary is sufficiently well-connected and therefore coherent. 
 
% We extract useful connectivity patterns for automatic summarization using a data-driven approach. 
% Given gold summaries, they represent entity relations between sentences of each summary via a graph whose nodes are sentences and edges are entity-based relations between sentences. 
% By applying a subgraph mining method to graph representations of gold summaries all subgraphs (coherence patterns) are extracted. 
% More frequent patterns are preferred to be observed in a machine generated summary more than other patterns. 
% So the frequency of patterns in gold summaries is used as an indicator of human preferences over patterns to be used for connecting sentences in a summary. 
% These patterns and their frequency are combined with other conditions for importance and diversity of sentences using the linear programming fashion. 
% We run our summarizers on DUC dataset that is commonly used for this task, and on PubMed corpus that consists of scientific articles. 
% Summarizing texts of scientific articles are taken difficult as multi-document summarization. 
% In addition, articles in PubMed corpus are associated with some summaries written by editors of the PubMed journal that can be used for evaluation. 
% The quality of summaries generated by our model is evaluated by ROUGE as a standard metric for the summary evaluation, and human judgments. 
% The results of our experiments show that our model outperforms its counterparts in both evaluations.

\paragraph{Coherence Pattern Mining.}
Here we explain how our coherence patterns are integrated into the summarizer proposed by \newcite{parveen15a}. 
We use notation $H$ to denote the dataset that consists of summaries written by humans for a set of texts.  
Notation $D=\lbrace \left( d_i, s_i \right) \rbrace$ refers to another dataset consisting of a set of document-summary pairs where the $i$th pair contains document $d_i$ and  its gold summary $s_i$ written by humans.  
We assume that each document has a title. 
Generally speaking, in automatic summarization models when an input text does not have any title, the first sentence of the text is taken as the title. 
Gold summaries can be employed to train a summarization model, and can also be used to evaluate summaries produced by the model during the evaluation phase. 
We make another assumption that documents in $H$ and $D$ are disjoint (i.e.\ there is no intersection among summaries or documents of these two datasets) but from the same genre. 
% because we want them to have similar styles of connectivity. 

We extract all coherence patterns from the human summaries that are collected in $H$. 
To this end, we represent all texts in this dataset by their own entity graph representations. 
Then we apply one-mode projection $P_U$ to entity graphs for obtaining projection graphs. 
We refer to the set of projection graphs that represent texts in $H$ by $GS_H$, which stands for the Graph Set of H. 
Afterwards, we use the gSpan method to extract all possible subgraphs from  graphs in $GS_H$. 
In Section \ref{sec:readability_assessment}, we have shown that frequencies of coherence patterns in a projection graph capture the connectivity style of the graph and correlate with readability ratings assigned by humans.  
Similarly, we take the subgraphs that frequently occur in $GS_H$ as the connectivity styles that are desired by humans to connect sentences in summaries. 
In order to model this, we weigh each coherence pattern based on its number of occurrences, i.e.\ count, in graphs in $GS_H$.  
The weight of a coherence pattern, $weight(p_u)$, is the sum of its counts in all graphs in $GS_H$ divided by its maximum count:

\begin{equation}
weight(p_u) = \frac{\sum_{k=1}^{M}{count(p_u,g_k)}}{\max_{k=1}^{M}{count(p_u,g_k)}},
\end{equation}
where $M$ is the number of graphs in $GS_H$, and $g_k$ indicates the $k$th projection graph in $GS_H$.
The nominator of the weight function counts the number of occurrences of $p_u$ in all graphs in $GS_H$. 
The denominator diminishes the weight of a coherence pattern if it  occurs in a few graphs of $GS_H$. 
In an extreme case, if a pattern occurs only in one graph in the graph set then $max_{k=1}^{q}{count(p_u,g_k)}$ is equal to $\sum_{k=1}^{q}{count(p_u,g_k)}$, so the weight of the pattern becomes one. 
If a pattern occurs in many graphs in $GS_H$ the denominator becomes smaller than the nominator, therefore the weight becomes greater than one. 
The weights of coherence patterns are not on the same scale.  
So we normalize the weights by 
\begin{equation}
z = \frac{x-\mu}{\sigma},
\end{equation}
where $\mu$ and $\sigma$ respectively are the mean and the standard deviation of all weights. Variable $x$ is the weight of a pattern.   
Finally a sigmoid function
\begin{equation}
 g(z) = \frac{1}{1+exp(-z)},
\end{equation}
scales weights to a value between $0$ and $1$. 

\paragraph{Summary Generation.}
Assume that we want to produce a summary for document $d$ from data set $D$. 
\newcite{parveen15a} develop an Integer Linear Programming (ILP) to extract the best possible subset of sentences with respect to importance, non-redundancy and coherence factors. 
To formulate the problem in ILP we represent all sentences in input document $d$ by set $S = \lbrace s_0,s_1,...,s_n \rbrace$ where $s_i$ is a boolean variable whose value represents if the $i$th sentence of document $d$ is selected for the summary or not.  
Set $E=\lbrace e_1, e_2,...,e_m \rbrace$ is a set of boolean variables representing entities in a text. 
The value of variable $e_i$ represents if its associated entity is mentioned in the selected sentences or not. 
Set $P= \lbrace p_1,p_2,..., p_k \rbrace$ is a set of boolean variables which are associated with coherence patterns. 
A true value of a variable in this set indicates that the pattern associated with the variable is a subgraph in the projection graph of the generated summary. 
We consider different weights, i.e.\ $\lambda_I$, $\lambda_R$, and $\lambda_C$, for the major factors of good summary, i.e.,\ importance, non-redundancy and pattern-based coherence.  
The objective function of ILP is as follows:

\begin{equation}
\max(\lambda_I f_I(S) + \lambda_R f_R(E) + \lambda_C f_C(P )),
\end{equation}
where $f_I(S)$ is the function that measures the importance of the selected sentences, $f_R(E)$ measures the redundancy among the selected sentences with respect to selected entities, and $f_C(P)$ measures the coherence of the selected sentences with respect to mined coherence patterns from dataset $H$. 

The importance function, $f_I(S)$, is calculated by considering the ranks of selected sentences for a summary:

\begin{equation}
f_I(S) = \sum_{i=1}^{n}{Rank(sent_i) \cdot s_i},
\end{equation}
%
where $Rank(sent_i)$ represents the rank of sentence $sent_i$ with respect to other sentences. 
Parameter $n$ is the number of sentences in the input document $d$.  

The ranks of sentences are calculated  by the \mbox{Hyperlink-Induced} Topic Search (HITS) algorithm.
HITS algorithm is developed by \newcite{kleinberg99} for ranking web pages considering the way they link one another. 
\newcite{kleinberg99} categorized web pages in two groups:  Authorities, which are informative web pages; and Hubs, pages that link to informative web pages\footnote{The idea behind Hubs and Authorities stemmed from a particular insight into the creation of web pages when the Internet was originally forming; that is, certain web pages, known as hubs, served as large directories that were not actually authoritative in the information that they held, but were used as compilations of a broad catalog of information that led users direct to other authoritative pages \cite{}.}.
Here, authorities are sentences and hubs are entities.  
The entity graph representation of document $d$ encodes the connections among sentences and entities in the document. 
Initial ranks for sentences are as follows:

\begin{equation}
Rank_{init}(sent_i)= 1 + sim (sent_i, title),
\end{equation}
where $sim(sent_i, title)$ is the cosine similarity between $sent_i$ and the title of document $d$. 
Initial ranks for all entities are set to one. 
After applying the HITS algorithm to the entity graph using the above initialization, the final ranks of sentences are taken as their importance. 

% Intuitively, if the summary has unique information in every sentence then the summary is non-redundant.
The non-redundancy function in the objective function, $f_R(E)$,    
is measured as follows:

\begin{equation}
\label{eq:redundancy-function}
f_R(E) = \sum_{j=1}^{m}{e_j},
\end{equation}
where $m$ is the number of entities in the input document. 

The summary contains non-redundant information if it includes only unique entities. 
The other interpretation of Equation \ref{eq:redundancy-function} is that if a summary contains more entities, it is covering more details of the document. 

The coherence function in the objective function, $f_C(P)$, measures the coherence of the summary that is obtained by concatenation of selected sentences in the order that they appear in the input document. 
This function uses coherence patterns and their weights, which are extracted from dataset $H$, as follows:

\begin{equation}
f_C(P) = \sum_{u=1}^{U}{weight(pat_u) \cdot p_u},
\end{equation}
where $p_u$ is the boolean variable associated with coherence pattern $pat_u$, and $weight(pat_u)$ is the weight of this pattern, which is basically the frequency of pattern $pat_u$ in graph set $GS_H$. 
The value of boolean variable $p_u$ is true, or one, if pattern $pat_u$ is a subgraph of the projection graph representation of selected sentences from the input document.  
Computing the value of $p_u$ is challenging because list of selected sentences at different optimization states is not explicit, so building the entity and projection graphs over the selected sentences at different states is impossible. 
However, since the projection graph of selected sentences at different states of ILP is a subgraph of the projection graph of the input document, we can define some constrains for our ILP to check if a coherence pattern occurs in a subgraph of the projection graph of the input document that only consists of nodes associated with selected sentences or not. 
In following, we explain constraints that are used in our ILP formulation. 

\paragraph{Constraints.}
%
Here we define all constraints over variables of our model to complete our ILP formulation of the summarization task. 
The first constraint limits the length of the summary:

\begin{equation}
\sum_{i=1}^{n} l_i \cdot s_i \le l_{max}
\end{equation}
where $l_{max}$ is the maximal permitted length of the summary and $l_i$ is the length of the sentence associated with boolean variable $s_i$.  
If $l_{max}$ is defined based on the number of words in a summary then $l_i$ is the number of words in the corresponding sentence.  
If $l_{max}$ is defined based on the number of sentences in a summary then it is sufficient to take each sentence as one unit, i.e.\ $l_i=1$. 

The constraint in Equation \ref{eq:const-2} ensures that if the $i$th sentence of document $d$ is selected, i.e.\ $s_i = 1$, all entities that are mentioned in the sentence, shown by $E_i$, are also selected. 

\begin{equation}
\label{eq:const-2}
( \sum_{e_j\in E_i}{e_j} )  \ge (|E_i| \cdot s_i) \text{   for   }i = 1,...,n,
\end{equation} 
where $|E_i|$ is the number of entities in the sentence.  

Similarly if an entity is selected to be mentioned in the summary then at least a sentence which contains a mention of the entity is selected as well:   

\begin{equation}
(\sum_{s_i \in S_j}{s_i}) \ge e_j\text{ for }j = 1,...,m,
\end{equation}
where $S_j$ represents the set of binary variables of sentences whose nodes in the entity graph representation of the document are connected to the entity node associated with $e_j$.  

In order to define constrains for involving coherence patterns in the optimization process, we adapt the graph matching algorithm proposed by \newcite{lerouge15}.
This algorithm uses ILP to check if a pattern is a subgraph of another graph. 
We need to consider more criteria to check if a pattern occurs in a subgraph of a projection graph where the subgraph consists of only selected nodes. 

To model the graph matching problem between projection graph $g=(V_{g},E_{g})$ and patterns $p_{u}=(V_{p_{u}},E_{p_{u}})$, two kinds of mapping binary variables are used: 

\begin{itemize}

	\item 
	For each pair of nodes $i \in V_{p}$ and $k \in V_G$, there is a variable $x_{i,k}$, such that $x_{i,k} = 1$ if nodes $i$ and $k$ are matched together, $0$ otherwise. 

	\item For each pair of edges $(i,j) \in E_{p}$ and $(k,l) \in E_G$, there is a variable $y_{ij,kl}$, such that $y_{ij,kl} = 1$ if edges $(i,j)$ and $(k,l)$ are matched together, $0$ otherwise.

\end{itemize}

Figure \ref{fig:mapping-var} illustrates these matching variables. 

\begin{figure}[!ht]
	\begin{center}

		\begin{tabular}{c}
			\begin{tikzpicture}[shorten >=1pt,->,scale=0.5]  
		        \tikzstyle{node}=[circle,thick,draw=black!75,fill=black!10,minimum size=5mm]
		        \tikzstyle{edge}=[draw, thick]
		    	\begin{scope}
			         \node [node] (a) at (0,4) {\tiny{$a$}};
			         \node [node] (b) at (4,4) {\tiny{$b$}};
			         \node [node] (c) at (2,0) {\tiny{$c$}};
			         \path[edge] (a) to  (b);
			         \path[edge] (a) to  (c);
			            
			         \node [node] (s1) at (10,4) {\tiny{$s_1$}};
			         \node [node] (s2) at (13.5,4) {\tiny{$s_2$}};
			         \node [node] (s3) at (15,1.2) {\tiny{$s_3$}};
			         \node [node] (s4) at (11.8,-1) {\tiny{$s_4$}};
			         \node [node] (s5) at (8.5,1.2) {\tiny{$s_5$}};

			         \path[edge] (s1) to (s3);
			         \path[edge] (s2) to (s3);
			         \path[edge] (s2) to (s4);
			         \path[edge] (s2) to (s5);
			         
			         \path[edge,dashed, bend left=30] (a) to  [above] node[font=\tiny] {$x_{a,s_2}=1$} (s2);

			         \path[edge,dashed] (c) to  [below] node[font=\tiny] {$x_{c,s_5}=1$} (s5);

			         \path[edge,dashed, bend left=10] (1,2) to  [below] node[font=\tiny] {$y_{ac,s_2s_5}=1$} (10.2,2.5);
		         \end{scope}

		      \end{tikzpicture}
		      \\
		      ($p_u$) \hspace{2cm} ($G$)
		\end{tabular}
	\end{center}
   \caption{An illustration of matching variables to overlay graph $G$ with coherence pattern $p_u$.}
   \label{fig:mapping-var}

\end{figure}

Given the above variables, we need to define some constrains in order to check if pattern $p_u$ is an induced subgraph of the selected nodes in projection graph $g$. 
To do so, we borrow constrains from \newcite{lerouge15} to check if the pattern is an induced subgraph of the projection graph or not, then we add some constrains to make sure that the pattern is matched with a subgraph that contains only selected nodes. 

\begin{itemize}
\item Every node of the pattern matches at most to one unique node of the graph:

\begin{equation}
\sum_{k\in V_g}x_{i,k} \leq 1 \quad \forall i\in V_{p_{u}},
\end{equation}

\item Every edge of the pattern matches at most to one unique edge of the graph:

\begin{equation}
\sum_{kl\in E_g}y_{ij,kl} \leq 1 \quad \forall (i,j)\in E_{p_{u}},
\end{equation}

\item Every node of the graph matches at most to one node of the pattern:

\begin{equation}
\sum_{i\in V_{p_{u}}}x_{i,k} \leq 1 \quad \forall k\in V_g,
\end{equation}

\item A node of pattern $p_u$ matches a node of graph $g$ if an edge originating from the node of $p_u$ matches an edge originating from the node of $g$:

\begin{equation}
\sum_{kl \in E_g}y_{ij,kl} =  x_{i,k}\textit{  }\forall k \in V_g, \textit{  }\forall ij \in E_{p_{u}},
\end{equation}

\item A node of pattern $p_u$ matches a node of graph $g$ if an edge targeting the node of $p_u$ matches an edge targeting the node of $g$:

\begin{equation}
\sum_{kl \in E_g}y_{ij,kl} =  x_{j,l}\textit{  }\forall l \in V_g,\textit{  }\forall (i,j) \in E_{p_{u}},
\end{equation}

\item Following constraint ensures that the model extracts induced patterns.  
Pattern $p_{u}$ is an induced subgraph of graph $g$ if $p_{u}$ contains all possible edges that are present in $g$. 
So

\begin{equation}
\sum_{i \in V_{pat_{u}}}x_{i,k} + \sum_{j \in V_{pat_{u}}}x_{j,l} - \sum_{(i,j)\in E_{pat_{u}}}y_{ij,kl} \leq 1
 \quad\textit{  }\forall (k,l)\in E_g
\end{equation}
\end{itemize}

So far, our constrains check whether the pattern is an induced subgraph of the projection graph. 
But we must also check if the pattern occurs in a subgraph of the projection graph such that the subgraph contains only selected sentence nodes for producing the summary. 
Introduced constraints up to now are not sufficient to check this. 
So we define some more constraints in this regard:

\begin{itemize}

\item If sentences $s_{k}$ and $s_{l}$ are selected for the summary then the edge between them must be selected $(z_{kl}=1)$ as well.
\begin{equation}
 s_{k} \cdot s_{l}=z_{kl} \quad \forall k,l \in V_{g}
\end{equation}

\item Pattern $p_u$ is present in the summary ($p_u=1$) if and only if one of its instances in the projection graph is included in the summary, i.e.,\ some of the selected sentence nodes must be present in an instance of pattern $p_{u}$.
Let $|V_{p_{u}}|$ be the number of nodes and $|E_{p_u}|$ be the number of edges in pattern $p_{u}$ then this constraint can be formulated as follows:

\begin{equation}
\underset{i \in V_{p_u}}{\sum} \underset{k \in V_g}{\sum} s_k \cdot x_{i,k}+\underset{ij \in e_{p_u}}{\sum} \underset{kl \in E_g}{\sum} z_{kl} \cdot y_{ij,kl} = p_{u}(|V_{p_u}|+|E_{p_u}|)
\end{equation}

\item If a sentence node is selected then it must match a node of at least one of the patterns:

\begin{equation}
\sum_{p_{u} \in P} \sum_{i \in V_{p_{u}}} x_{i,k} \geq s_{k} \quad \forall k \in V_{g}
 \end{equation}
\end{itemize}

Now we can set up our experiments for evaluating our approach to coherence patterns on the summarization task. 

\paragraph{Data.}
We evaluate our model on two datasets:  \emph{PLOS medicine} and \emph{DUC 2002}. 
The PLOS medicine dataset consists of $50$ scientific articles.  
We are motivated to evaluate our model on scientific articles because of the growth in the number of scientific publications in different research fields.  
A summarizers assist researchers to have an informative and coherent gist of long scientific articles. 
Moreover, summarizing scientific articles is as difficult as multi-document summarization because scientific articles are tend to be long and the important information is spread all over an article,  unlike the distribution of information in a news article \cite{teufel02}. 
The reason that we selected the PLOS medicine dataset is that articles in this dataset are accompanied by summaries written by editors of the month. 
Editors' summaries have a broader perspective than abstracts of articles.  
We use scientific articles and their corresponding editor's summaries as dataset $D$ in our formulation for the summarization task (see Section \ref{sec:auto-summarization}). 
Abstracts of scientific articles can be taken as summaries of articles as well, which are coherent because they are written by humans. 
we collect abstracts of $700$ scientific articles from the PubMed\footnote{\url{http://www.ncbi.nlm.nih.gov/pmc/tools/ftp/}} corpus, which is in the \mbox{bio-medicine} field, to mine coherence patterns and compute their weights. 
This dataset of abstracts is dataset $H$ in our formulation for the summarization task.  
The articles of this dataset do not overlap with articles in PLOS Medicine dataset. 

We also evaluate our model on the DUC 2002 dataset that has been annotated for the Document Understanding Conference 2002. 
It contains $567$ news articles for summarization. 
Every article in this dataset is associated with at least two gold summaries written by humans. 
This is dataset $D$ in our formulation and we use this dataset for the evaluation purposes. 
We use human summaries in the DUC 2005 dataset, which has $300$ articles, to mine coherence patterns and then calculate the weights of patterns.  
This is dataset $H$ in our formulation. 

DUC 2002 articles are shorter than \emph{PLOS Medicine}\ articles (25 vs.\ 154 sentences average\ length). 
In scientific papers clarity is paramount, so the author will endeavor to state things explicitly and avoid ambiguity. 
Authors of scientific articles repeat terminologies to be explicit.     
In contrast, in literature, word repetition is not only uncommon, but it is usually a sign of bad writing. 

\paragraph{Experimental settings.}
In the preprocessing phase, we extract texts from scientific articles by removing all figures, tables, references and \mbox{non-alphabetical} characters.
For both datasets, we use the Stanford parser \cite{klein03b} to parse sentences. 
We represent each text by its entity graph that is obtained based on its entity grid representation. 
We employ the Brown coherence toolkit \cite{elsner11b} to build entity grids from parse trees.  
We use gSpan \cite{yanxifeng02} to extract all coherence patterns from the projection graphs in $GS_H$. 
We use coherence patterns with three and four nodes to which we refer as 3-node and 4-node patterns respectively. 
The optimization is formulated as Mixed Integer Programming (MIP) that deals with quadratic constraints. 
We use Gurobi \cite{gurobi14} to solve the MIP optimization problem.
We determine the best values for $\lambda_{I}$, $\lambda_R$, and $\lambda_{c}$ on the development sets.
$\lambda_{I}=0.4$, $\lambda_R=0.3$, and $\lambda_{c}=0.3$ are the best weights for the \emph{PLOS Medicine}\ development set. 
Weights for the DUC 2002 development set are $\lambda_{I}=0.5$, $\lambda_R=0.2$ and $\lambda_{c}=0.3$.
When a summary is produced all pronouns are substituted with their antecedences using the pronoun resolution system provided by \newcite{martschat13}. 
We limit the length of summaries to $5$ sentences,  where we compare our system with the \mbox{state-of-the-art} systems on PLOS Medicine. 
However, since the word length limit of a summary is more reasonable than the sentence length limit of a summary, in addition we compare the examined summarization models where the length of a summary is restricted to the average length of editor's summaries in the dataset ($750$ words). 

\paragraph{Compared summarization systems.}
We compare our summarization system, which is enriched with coherence patterns, with the following summarization systems: 

\begin{itemize}
	\item \emph{Random}: This model selects sentences randomly from the input document;

	\item \emph{Lead}: This model takes the top n\% of the sentences of the input document;

	\item \emph{Maximal Marginal Relevance (MMR)} \cite{carbonell98}: This model uses a \mbox{trade-off} between relevance and redundancy to rank sentences. 
	 To do this, the model defines a linear ranking function as:
	 \begin{equation}
	 MMR(s_i) = \mathtt{\argmax}_{s_i}\lbrace \gamma sim(s_i,title) + (1-\gamma)\mathtt{\max}_{s_j}sim(s_i,s_j)) \rbrace 
	 \end{equation} 
	 where $\gamma$ is the trade-off factor. 
	 If $\gamma$ equals to one then the sentences in the input document are ranked merely based on their similarity with the title, which means ranking based on relevance. 
	 If $\gamma$ equals to zero, sentences are ranked based on the similarity among themselves, which can be interpreted as redundancy. 

	\item \emph{Text-Rank} \cite{mihalcea04b}: This graph-based model allows for ranking over sentences that is recursively computed based on the information drawn from the entire text. 
	It represents the input document by a graph whose nodes represent sentences and edges indicate existence of content overlaps between sentences. 
	Edges are weighted by the number of content words that overlap between sentences. 
	The ranking of sentences are measured by computing the importance of its corresponding node in the graph. 
	The node importance in the graph is computed based on the global information which is recursively drawn from the entire graph. 
	The importance score of each node in each recursion is updated with respect to the importance score of its neighbors in the graph. 
	
	\item \emph{EntOD} \cite{parveen15a}: 
	This model uses ILP in order to optimize the summary based on importance, non-redundancy, and coherence. 
	The importance and non-redundancy components are identical with with these components in the summarization system that is explained here. 
	The only difference between the EntOD system and our summarization system is in the coherence component. 
	In EntOD, the input document is represented by the entity graph to encode \mbox{entity-based} relations among sentences. 
	Then the outdegree of sentence nodes in the projection graph of an input document, as the coherence measure of each sentence. 
	That is why we refer to this model as EntOD. 

	\item \emph{TopicOD} \cite{parveen15b}: 
	This summarization system is as same as the EntOD system except the way that texts are represented. 
	This model uses topical graphs, instead of entity graphs, to encode topical relations among sentences. 
	Topical graphs are bipartite graphs consisting of two sets of nodes: sentences and topics. 
	The outdegree of each sentence in weighted projection graphs are taken as the coherence measure of the sentence.

	\item \emph{Mead} \cite{radev04b}: This model assigns a score to each sentence of the input document using three other scores: the centroid score (which is a measure of the centrality of a sentence to the overall topic of the input document), the position score (which decreases linearly as the sentence gets farther from the beginning of the input document), and the \mbox{overlap-with-first} score (which is the inner product of the \mbox{TF*IDF-weighted} vector representations of a sentence and the first sentence (or title, if there is one) of the input document. 
	MEAD discards sentences that are too similar to other sentences (based on the cosine similarity). 
	Any sentence which is not discarded due to high similarity and which obtains a high score (within the specified compression rate) is included in the summary. 
	
\end{itemize}


\paragraph{Results.}
We evaluate the summarization system, which is enriched by coherence patterns in, two ways. 
First, we use ROUGE scores to compare our summarizer with other models. 
Second, we explicitly evaluate the coherence of summaries by human judgements.

\paragraph{ROUGE assessment.}
The ROUGE score \cite{linchinyew04} is a standard evaluation metric for automatic text summarization. 
It principally measures word overlaps between gold summaries (usually generated by humans) and summaries produced by a model. 
ROUGE-1, ROUGE-2 and ROUGE-SU4 are three versions of ROUGE that are popularly reported for comparing different summarization systems. 
ROUGE-1 and ROUGE-2 capture unigram and bigram overlap between a gold summary and a produced summary. 
These are meant to assess informativeness. 
ROUGE-SU4 captures skip-bigram plus unigram-based co-occurrence statistics. 
We refer interested readers to  \newcite{graham15} for more explanations about evaluation metrics for the summarization task. 

Table \ref{table:plos_5len_editor} reports ROUGE scores of different systems on the \emph{PLOS Medicine} dataset where the length of summaries is limited to five sentences. 
Our summarization system that uses three nodes outperforms other systems.  


\begin{table}[!ht]
	\begin{center}
		\begin{tabular}{lcc}
		\toprule
		Systems 			& ROUGE-SU4 &ROUGE-2\\
		\midrule
		Lead 				& 0.067 	& 0.055  \\
		Random 				& 0.048  	& 0.031  \\
		MMR 				& 0.069 	& 0.048  \\
		TextRank 			& 0.068  	& 0.048  \\
		Mead 				& 0.084 	& 0.068  \\
		EntOD 				& 0.131		& 0.098  \\
		TopicOD				& 0.129 	& 0.095  \\
		\textbf{3-node} 				& \textbf{0.135} & \textbf{0.103} \\
		\bottomrule
		\end{tabular}
	\end{center}
	\caption{\emph{PLOS Medicine}, editor's summaries with \textbf{5 sentences}.}
	\label{table:plos_5len_editor}
\end{table}

Table \ref{tab:plos-750words} shows the performance of different systems with $750$ words limit for a summary where editor's summaries are taken as gold standard. 
We calculate different variations of ROUGE-2 and ROUGE-SU4. 
These variations demonstrate the effect of stop words and stemming in the ROUGE calculation.
For the sake of brevity, we use the notation ``SW'' to refer to stop words and ``SM'' to refer to word stemming.  
``SW--'' shows that stop words are not taken into account in ROUGE calculation; ``SW+'' is the opposite. 
``SM--'' shows that Porter Stemmer is not applied to summaries in ROUGH calculation, ``SM+'' is its opposite. 
 
Our models achieves the best performance in comparison to other examined systems with respect to all variations of ROUGE. 
When we integrate coherence patterns with three nodes into the summarizer, i.e.\ 3-node, the summarizer significantly outperforms EntOD that uses the outdegree of sentence nodes as the coherence feature. 
These results confirm our intuition that the outdegree of nodes in the projection graph of the input document is not a powerful representative for the coherence of selected sentences for a summary. 
3-node works better than EntOD basically because our coherence patterns capture the connectivity style among selected sentences from the input document for the summary, whereas
the outdegree measures to what extend a sentence is connected to other sentences in the input document, rather than the summary. 
Moreover, the outdegree does not capture how sentences should be connected to have a coherent summary. 

\begin{table}[!ht]
	\begin{center}
		\begin{tabular}{lr@{}lrrr||r@{}lrrr}
		\toprule
		\emph{PLOS Medicine}& SW--& & SW-- & SW+ & SW+& SW-- & & SW-- & SW+ & SW+ \\
		Editor's summaries  & SM-- & & SM-- &  SM+ & SM-- &  SM+  & & SM-- &  SM+  & SM-- \\
		\midrule
		&& \multicolumn{4}{c||}{ROUGE-SU4 ($\ast p<.05$)} & \multicolumn{4}{c}{ROUGE-2 ($\ast p<.01$)}\\
		\midrule
		Random &  0.140& & 0.113 & 0.169  & 0.153 &  0.102 & & 0.088 & 0.125 & 0.116 \\
		Lead & 0.191 & & 0.158 & 0.246 & 0.222  & 0.158 & & 0.140 &0.185 &0.171   \\
		MMR & 0.183& & 0.149 & 0.240 & 0.215 & 0.141 & & 0.125 & 0.171 &0.157 \\
		TextRank & 0.148& & 0.104 & 0.161 & 0.159 & 0.115 & & 0.084 &0.126 & 0.118\\
		Mead & 0.197 & & 0.165 & 0.246 & 0.222& 0.156 & &0.139 & 0.186 & 0.172 \\
		EntOD & 0.204&* & 0.167 & 0.254& 0.228 &0.160 &* & 0.145 &0.187 & 0.173\\
		TopicOD & 0.195 & &0.161 & 0.231 &0.206 & 0.157 &  & 0.140 &0.169 & 0.165 \\
		3-node &0.215& * &0.178& 0.268& 0.241& 0.172 & * & 0.153 & 0.200 &0.184 \\
		\textbf{4-node} & \textbf{0.218}& & \textbf{0.179} & \textbf{0.270} & \textbf{0.245}  & \textbf{0.175} & & \textbf{0.156} & \textbf{0.201} & \textbf{0.187} \\
		\bottomrule
		\end{tabular}
	\end{center}
	\caption{ROUGE scores on \emph{PLOS Medicine} with \textbf{750 words}.}
	\label{tab:plos-750words}
\end{table}

When we integrate 4-node coherence patterns into the summarizer, the summarizer works slightly better than when 3-node patterns are combined; This confirms that large subgraphs capture more information about the connectivity style of nodes in a projection graph and therefore the coherence of sentences.  
However, this improvement is not statistically significant. 
4-node patterns are less likely than 3-node patterns to occur in a subgraph of the projection graph where the subgraph contains only selected nodes for the summary. 

The summarizer that is enriched by our coherence patterns outperforms \emph{Mead} as one of the state-of-the-art summarization systems. 
On average summaries produced by \emph{Mead} contains less number of sentences than summaries produced by 3-node patterns (17.5 vs 27.2 sentences per summary).
This shows that \emph{Mead} selects longer sentences in comparison to our 3-node patterns.  
Long sentences are more complex and less readable. 
They may also contain more irrelevant entities than shorter sentences because they are longer. 

Table \ref{tab:summary-duc} shows the results on DUC 2002 of well-performed  systems in the previous experiment. 
In addition to other models, we compare our model to \emph{NN-SE} that utilizes a neural network hierarchical document encoder and an \mbox{attention-based} extractor to extract sentences from a document for a summary \cite{chengjianpeng16}.

ROUGE scores of our summarization approach, i.e.\ 3-node in Table \ref{tab:summary-duc}, on this dataset surpass the scores of other summarization systems. 
This shows that our system performs well even in a different domain and with considerably shorter input documents. 
Our model outperforms the \emph{NN-SE} system because our model explicitly takes into account the connectivity of selected sentences in the sentence extraction phase. 
We only use 3-node subgraphs on this dataset because the summaries are supposed to be very short. 
So 3-node subgraphs are sufficient to capture the connectivity style of selected sentences. 


\begin{table}[!ht]
	\begin{center}
		\begin{tabular}{lccc}
			\toprule
			Systems 					& ROUGE-1 	& ROUGE-2 	& ROUGE-SU4 \\
			\midrule
			Lead 						& 0.459 & 0.180 & 0.201	\\
			TextRank 					& 0.470 & 0.195 & 0.217	\\
			DUC 2002 Best 				& 0.480 & 0.228 & 		\\
			Mead 						& 0.445 & 0.200 & 0.210	\\
			EntOD						& 0.485 & 0.230 & 0.253 \\
			TopicOD 					& 0.481 & 0.243 & 0.242 \\
			NN-SE 						& 0.474 & 0.230 & 		\\
			\textbf{3-node} 						& \textbf{0.490} & \textbf{0.247} & \textbf{0.258}\\
			\bottomrule
		\end{tabular}
	\end{center}
	\caption{ROUGE scores on DUC 2002.}
	\label{tab:summary-duc}
\end{table}

\paragraph{Coherence Assessment.} 
Here we exclusively assess the coherence aspect of summaries by asking human judges to rank summaries that are generated by different systems. 
To this end, we ask four human judges\footnote{Human judges are one PostDoc, two PhD students and one Masters student in our NLP group.} to rank summaries of four different systems for ten different articles. 
The most coherent summary is assigned with rank $1$, the second best is assigned with rank $2$, the third best gets rank $3$, and the worst obtains rank $4$.
The four summarization systems are
\emph{3-node}, \emph{EntOD}, \emph{Text-Rank}, and \emph{Lead}.

The Kendall concordance coefficient (W) \cite{siegel88} over the rankings is calculated in order to measure the agreement between the human judges.  
We calculate Kendall's W for every scientific article, which is given to the human subjects. 
Then, we calculate the average of Kendall's W of scientific articles. 
The average Kendall's W is $0.6725$, which indicates a high level of agreement between human subjects.
Applying the $\chi^2$ statistical test shows that W is statistically significant (p\_value <.05).  This indicates that the rankings provided by the human judges are reliable and informative.
Table \ref{tab:summary-human} shows the overall average rankings summaries produced by a system received by human judges. 

\begin{table}[!ht]
	\begin{center}
		\begin{tabular}{lc}
		\toprule
		System 				&  Average Human scores \\
		\midrule
		TextRank 			& 3.950					\\
		EntOD 				& 2.325					\\
		\textbf{3-node}		& \textbf{1.875} 		\\
		Lead 				& 1.625					\\
		\bottomrule
		\end{tabular}
	\end{center}
	\caption{The average human scores evaluated on the PLOS Medicine dataset. Lower is better. 
	The bold line is our system.}
	\label{tab:summary-human}
\end{table}

\emph{Lead} obtains the best overall average rank because it extracts adjacent sentences from the beginning of the text. 
Hence, the summaries produced by this system are as coherent as the author intends them to be. 
Our summarizer, which is enriched with 3-node coherence patterns, follows LEAD by outperforming EntOD and TextRank.  
This shows that the integration of our coherence patterns into the summarization system yields texts that are more coherent in comparison with summaries that are produced by baseline summarizers such as EntOD that uses the average outdegree.  

\section{Summary}
\label{sec:summary}

In this chapter, we challenged the average outdegree metric that is heuristically defined by the entity graph model. 
The main intuition behind the usage of this metric is that documents whose projection graphs have higher average outdegrees are more coherent. 
We showed that the average outdegree of nodes in a projection graph is not sufficient to capture the connectivity style of nodes and consequently the perceived coherence of the corresponding document. 
Instead, we proposed novel coherence patterns that capture the entity-based connectivity style of sentences in documents. 
We employed projection graphs of texts in a corpus to encode the connectivity style of sentences.  
Then by applying a subgraph mining algorithm to all projection graphs of all texts, we mine all occurring subgraphs in these graphs as coherence patterns. 
We use the frequency of each coherence pattern in a projection graph as a representative feature of the connectivity style of nodes in the projection graph and consequently, a representative feature of the perceived coherence of the corresponding document. 

We evaluated our coherence patterns in two applications: readability assessment and extractive \mbox{single-document} summarization. 
In the former, we observed that frequencies of some coherence patterns are positively and some others are negatively correlated with readability ratings, which are assigned to texts by human judges. 
Positively correlated patterns mostly depict this intuition in texts that a sentence introduces some entities and its subsequent sentences elaborate each of them.  
Negatively correlated patterns roughly remind us the linear chain pattern in linguistics where a sentence is located between two unrelated sentences to make them connected. 
Although this pattern is useful but if it occurs too frequently in a document then it disturbs the coherence of the document. 
Our experiments showed that 4-node subgraphs are more predictive than 3-node subgraphs in ranking documents with respect to their readability. 
We believe that this is mainly because large coherence patterns have more capacity than small ones for encoding the connectivity style of nodes in projection graphs. 

In the summarization task, we examined our coherence patterns by integrating them into an existing summarization system that is developed on the entity graph representation of documents. 
This task was challenging  because we had to model the existence of our coherence patterns in a summary by defining several new constraints in linear programming.  
The results of our experiments on DUC 2002 as an standard dataset for summarization and PLOS Medicine as a corpus of scientific articles show that our coherence patterns improve the performance of the summarizer with respect to ROUGE and human evaluation. 


The key message of this chapter is that in order to capture the connectivity style of sentences in  a document, which is encoded via the graph representation of the text, coherence patterns, which are obtained automatically by applying a subgraph mining algorithm to graphs, are more useful than average outdegree, which is designed heuristically. 
Coherence patterns capture coherence by taking each sentence in its connections with other sentences in the summary. 
Our \mbox{data-driven} approach to coherence pattern mining enables us to extract patterns from documents that are provided for an application and collected in a dataset. 

We observe that 4-node subgraphs are better coherence patterns than 3-node subgraphs. 
However, more investigation is requited to be performed on how the size of subgraphs influences the performance of the model. 
The entity graph does not include mentions that are semantically related but are not coreferent. 
In addition, it is also restricted to only noun overlap relation among sentences in a text, while any lexical semantic relation between words in sentence can relate sentences. 
We follow these points in the following chapter of this thesis. 

The main contributions of the research in this chapter are:

\begin{itemize}
\item analyzing the power of the average outdegree in coherence measurement
\item proposing subgraphs of projection graphs as coherence patterns and their frequencies as coherence features 
\item evaluating the predictive power of coherence patterns in classifying coherent texts vs incoherent ones
\item showing that how coherence patterns can be utilized in readability assessment as a text quality evaluation task, and the document summarization task as an instance of text generation systems.   
\end{itemize}



% for sublime text 3
%!TEX root = diss.tex

\chapter{Coherence Modeling}
\label{ch:coherence}

Local coherence modeling is a crucial task for natural language processing with varying specifications over the years. 
This chapter gives related linguistic definitions, which are related to the task that is tackled in this thesis. 


\section{Problem Definition}
\label{sec:coh-def}

In this thesis, we tackle the problem of local coherence modeling. 
The popular definition of this task is to model how sentences in a text are related one another. 
This task has been the focus of the majority work in text processing (see Section \ref{sec:related_work}). 
Variations of the task consider different types of relations, such as rhetorical \cite{hovyeduard89} or lexical \cite{morris91}, between different spans of texts, such as clauses \cite{strube.col98} or sentence \cite{halliday76}, in various text types, such as dialogue \cite{wangxinhao13} or monologue \cite{barzilay08}. 
Here we give a formal definition of this problem, which will be used in the following chapters of this thesis. 

\subsection{Formal Modeling}

In order to provide a formal definition of the task, i.e.\ local coherence modeling in texts, we first need to give a definition of what we refer to as a text. 
In this thesis, the word text refers to formal written and monologue sequence of sentences that transmit a meaning as a whole.  
We assume that a text consists of more than one sentence. 

\begin{definition}
Text $T$ is a sequence of finite number of sentences $[s_0, s_1, s_2, ..., s_n]$ where the number of sentences is greater than 1, $n>0$.   
\end{definition}

Each sentence in the above definition of a text is a list of words that form a sentence structure. 

\begin{definition}
Sentence $s_i$ is a sequence of words $[w_0, w_1, w_2, ... , w_n]$ that form a sentence structure in the language. 
\end{definition}

An underlying assumption in research on text processing is that a text is more than the sum of its sentences. 
It is not sufficient to collect an arbitrary sequence of sentences in order to obtain a text. 
Sentences in a text are supposed to be related to one another to make a whole. 

\begin{definition}
A relationship function $R(s_i,s_j)$ indicates whether two given sentences in a text are related. 
The domain of this function is sentences in a text and its range is a binary value $
\lbrace 0,1\rbrace$. 
\end{definition} 

Having the above definition, relationships across all sentences in a text can be represented by a set $P$ containing relationships between any pairs of sentences in the text. 

\begin{definition}
Let $r_{ij}= R(s_i,s_j)$ indicates the relationship between a sentence pair $(s_i,s_j)$ in a text $T$, the set $P$ contains all $r_{ij}$ for any pair of sentences in $T$.
\end{definition}  

Although we define $P$ as a set but it can be partially structured, e.g.\ when sentence $s_i$ has to proceed sentence $s_j$ in a text. 


The distinction between texts with respect to their coherence is in the last resort a matter of degree \cite{haliday76}: Which one is more coherent? 
In order to rank texts with respect to their coherence, we need to capture patterns that frequently occur in well-written texts, and rarely in less coherent ones.  
Coherence patterns are template of relationships among sentences in texts, such that their frequencies assist to distinguish coherent texts from incoherent ones. 

\begin{definition}
A coherence pattern is a subset of relations $p \subseteq P$ occurring among sentences of a text.   
\end{definition}

We define a function to model how coherence patterns are extracted from a corpus of texts. 

\begin{definition}
Given a corpus $C$ which includes texts with different degrees of coherence, a pattern mining method $M$ extracts all subsets of relations that occur in texts in $C$. 
\end{definition} 

The output of the pattern mining process on a corpus of texts is a set of coherence patterns. 
The coherence of a text can be modeled by a vector of frequencies of these patterns in the text. 

\begin{definition}
Let $P=\lbrace p_0,p_1,p_2,...,p_m \rbrace$ be a set of extracted patterns from a corpus of texts $C$, the perceived coherence of each text $T$ is represented by a vector $\phi = <f_0, f_1, f_2,...,f_m>$, where $f_k$ is the frequency of pattern $p_k$ in text $T$. 
\end{definition}

Having vector representations of coherence lets us to employ machine learning models to rank texts. 
In Chapter \ref{ch:rel_work}, we describe different approaches to modeling relationships between a pair of sentences, i.e.\ $R(s_i,s_j)$, and how they represent the set of all relations in a text $P$.  
There, we also review how method $M$ is derived by different computational models. 
We employ a powerful representation method from the literature and develop our approach for extracting coherence patterns in Chapter \ref{ch:coh_patterns}. 
We further improve the predictive power of coherence patterns by a new approach to relationship representation among sentences $P$ in Chapter \ref{ch:lex_graph}. 

\section{The Linguistics of Coherence}

The aforementioned formal definition of the problem is sufficient for the research in this thesis to develop a representation of cohesive relations in a text, and extract coherence patterns. 
However, since coherence is a semantic property of a text, the definition needs to be related with linguistic properties of a text. 

Our aim is to develop an approach which provides a representation of the coherence of a text. 
Therefore we need to understand what aspects in sentences serve to relate sentences and how coherence patterns are modeled in linguistics of coherence. 
Therefore, we explain related linguistic properties that are required to complete our definition. 


\subsection{Text}

The first definition in our formal model of coherence is about text. 
In linguistic research the word ``text'' is used to refer to any passage, spoken or written, of whatever length that forms a unified whole \cite{halliday76}. 
In this thesis, we follow other coherence models \cite{barzilay08,guinaudeau13} and use the word ``text'' to denote a merely monologue written passage, which is more than one sentence.
One sentence texts, of course, do exist, like public notices, proverbs and advertising slogans and the like. 
An a sample text in Example \ref{ex:coh-one-sent-text}\footnote{Taken from \url{https://www.engvid.com/english-resource/50-common-proverbs-sayings/}, accessed 1 June 2018.}: 

\begin{examples}
    \label{ex:coh-one-sent-text}
    A journey of a thousand miles begins with a single step.
\end{examples}

However, due to texts consisting of one sentence only are fairly rare, we assume texts contains several sentences.  
We also assume that texts are written in a formal language, in contrast to informal like tweets\footnote{A post made on the social media application Twitter}. 

\subsection{Coherence}

Coherence is a crucial factor of a well-written text. 
It makes the text distinguishable from an unrelated sequence of sentences. 
We follow \newcite{stede12} and define coherence as a property of a text that is designed around a common topic. 
A coherent text discusses a sequence of topics in a structured way that a reader can recognize and relate to one another, and collectively render the text as a unified whole. 
Each topic is tending to occupy a (topical) segment of the text \cite{hearst97}. 
Coherence is defined based on the relations and structures of topical segments in a text. 
This structure is sometimes referred to as global, since it is coarse-grained and spans the entire text \cite{}. 
\newcite{lautamatti78} defines the term topic as what the sentence is about and the term comment as information about the topic.  
In general, however, defining the notion of topic, and recognizing topics and the boundaries between  text segments corresponding to them are not straight forward \cite{stede12}. 
We discuss some computational topical coherence model in Chapter \ref{ch:rel-work}. 


\subsection{Local Coherence}

From the linguistic viewpoint, a coherent text employs linguistic devices, more-readily identifiable linguistic signals, to relate sentences of a text to each other. 
These devices signal readers to interpret each sentence considering its relations with other linked sentences \cite{vandijk77}. 
Therefore, understanding the text implies uncovering these relationships.  
The way that linguistic devices are used to relate sentences in a text is known as local coherence. 
In some literature in text linguistics \cite{halliday76}, this phenomena is referred to as cohesion.   
\newcite{stoddard91} (chapter 2) argues that these two are not distinguishable and can be used interchangeably. 
\newcite{stede12} stats that signals of local coherence serve as indicators of topic continuity, consequently the absent of a surface relation is a sign of topic shift. 
Since the research in this thesis is about modeling local coherence, henceforth in this thesis it is referred to as coherence modeling, unless this is not clear from the context. 

Prominent cohesive devices can be grouped in grammatical and lexical relations between elements of sentences \cite{halliday76}. 
Grammatical relations are reference, substitution, ellipsis and conjunctions. 
Lexical relations include any lexical-semantic relation, such as repetition, synonym, antonym, and the like, between words of sentences. 
Reference cohesive devices are also known as entity-based relations, with this intuition that related sentences in a text keep referring to the same named entity. 
The sample text in Example \ref{ex:coh-ref}\footnote{Taken from \url{https://web.stanford.edu/class/archive/cs/cs224n/cs224n.1162/handouts/cs224n-lecture11-coreference-6up.pdf}, on June 2 2018.} shows how entity-based relation link sentences. 

\begin{examples}
	\label{ex:coh-ref}
	\textbf{Mr.\ Obama} visited the city. \\
	\textbf{The president} talked about Milwaukeeâ€™s economy. \\
	\textbf{He} mentioned new jobs. \\
\end{examples} 


One of the popular entity-based frameworks for local coherence modeling is Centering Theory \cite{grosz95}. 
The main hypothesis of this theory is the center that at any given point in a text is most salient entity.  
The center captures the focus of attention in the reader mind \cite{grosz95}.
Centering Theory accounts of the process of flowing the center in a text. 
The original centering theory (for English texts) see the grammatical role as the most important linguistic sign of the text center. 
Specifically, the grammatical subject is taken the default position for the text center. 
Depending on the configuration of grammatical roles in adjacent sentence, \newcite{brennan87} define four different types of transitions for the text center. 
These transitions capture the smoothness of the center move from one sentence to another. 
When a latter sentence focuses on the topic, i.e.\ center, transition is Continue, the other types involve topic shift: Retain, Smooth Shift, and Rough Shift. 
Centering has been applied directly in models of coherence \cite{karamanis04}.  
However, since it requires human annotations for transitions between sentences, other models employ the basic Centering principles as soft constraints or features in a probabilistic framework such as the Entity Grid \newcite{barzilay05}, which we discuss in more detail in Chapter \ref{ch:rel-work}.

Further research shows that grammatical role information are far less predictive for tracking the text center in German, as a free word order language \cite{strube.acl96}. 
Instead the functional information structure \cite{danes74} are considered. 
This structure captures flows between given information vs. new information in a text. 
Some information in a sentence is known or old, because of it is discussed by preceding sentences of the sentence, and some information are new. 
The functional information structure is explained by \newcite{halliday76} as theme-rheme relations in a text. 
Theme can be taken as given information, as a point of the text departure, and rheme is (almost) similar to new information, as clarity information in the theme. 
While theme conveys information that is initially introduced in discourse, rheme presents specific 
information regarding the theme. 
As the theme-rheme movement continues through a text, ideas in the text are expected to flow along smoothly and are easier for the reader to understand. 
Thematic relations between sentences in texts reveal some patterns \cite{danes74}, which are called  coherence patterns.
In Chapter \ref{ch:coh-patterns}, where we define our coherence patterns, we give more explanation about functional information structure \cite{danes74} in texts. 

The other perspective of local coherence is lexical cohesion, which cohesive effect based on lexical-semantic relations between words. 
An advantage of lexical cohesion, on contrary to entity-based models, is that it requires no annotation at all; they are accessible directly from the text. 
The insight of local coherence on the grounds of lexical relations is that content words in a text do not occur independently of one another, but bear semantic similarity because of common topic. 
A form of lexical cohesion is reiteration, which involves different type of lexical relations such as repeating a word, using a synonym of a word, employing a superordinate word, and using a general word. 
Example \ref{ex:coh-lex} is taken from \cite{halliday78} to illustrate these relations:

\begin{examples}
	\label{ex:coh-lex}
	(a) Repetition: There was a large \textbf{mushroom} growing near her, about the same height as herself; and when she had looked under it, it occurred to her that she might as well look and see what was on the top of it.\\
	She stretched herself up on tiptoe, and peeped over the edge of the \textbf{mushroom}, ... 

	(b) Synonymy: Accordingly ... I took leave, turned to the \textbf{ascent} of the peak. \\
	The \textbf{climb} is perfectly easy. 

	(c) Superordinate: Henry's bought himself a new \textbf{Jaguar}. \\
	He practically lives in the \textbf{car}. 

\end{examples} 

In (c) the word ``car'' is a superordinate, any word whose meaning includes that of the earlier one, of ``Jaguar'', as vehicle is a superordinate of the car, spoon of teaspoon, and the like. 
The boundary between the reiteration type of lexical cohesion and reference type in grammatical relations, i.e.\ entity-based relations, is by no means clearcut\footnote{However, properly speaking, reference is irrelevant to lexical cohesion. As we discuss later lexical cohesion relationship between two items does not need to imply a coreferent relationship.} \cite{halliday78}. 
This can slightly clarify the reason that for purposes of the research in this thesis local coherence and cohesion are largely synonymous.

It is not necessary for two lexical occurrences to be coreferent, however, in order to for them to be cohesive. 
Consider Example \ref{ex:coh-nonref} from \newcite{halliday78}(p.~282). 
In (a) word ``boy'' and  word ``boys'' are not coreferent, however, their semantic relationship serves to link the sentences. 
This relationship is not in any way dependent on the presence of other items; it is not the wriggling that provides the context, as (b) shows. 

\begin{examples}
	\label{ex:coh-nonref}
	Why does this little boy have to wriggle all the time? \\
	(a) Good boys don't wriggle. \\
	(b) Boys should be kept out of here. \\
\end{examples} 

This leads to a systematic relationship between a pair of words, that is because the words are frequently occur in similar text context. 
For instance, words ``boy'' and ``girls'' in Example \ref{ex:coh-collocation} \cite{halliday76}(p.~285) relate the sentence, although they are not coreferent, or even synonym. 

\begin{examples}
	\label{ex:coh-collocation}
	Why does this little boy have to wriggle all the time? \\
	Girls don't wriggle. 
\end{examples}

In summary, there is a local coherence relation between any pair of lexical items that stand to each other in some lexical-semantic relations. 
This includes any type of relations, such as relations between word pairs shown in Example \ref{ex:coh-word-pairs} \cite{halliday76} (p.~285). 

\begin{examples}
	\label{ex:coh-word-pairs}
	rail ... road \\
	car ... brake \\
	try ... succeed \\
	walk ... drive \\
	Tuesday ... Thursday \\
	like ... hate \\
	red ... green 
\end{examples}

For textual purposes, it is (almost) sufficient to know that a pair of words are in a relationship, rather than the type of relation \cite{halliday76} (p. 285).  
\newcite{hoey91} examine how lexical cohesive elements make a text organized, and contribute to local coherence. 
He shows that relations between semantically related words in a text can make patterns in texts. 
In Chapter \ref{ch:rel-work}, we survey some related computational models of lexical cohesion in texts. 

\subsection{Coherence Patterns}
\textbf{stodarrd a and some part from danes}

An increasing number of researchers and practitioners in natural language processing face the prospect of having to work with entire texts, rather than individual sentences. 
While it is clear that text must have useful structure, its nature is less clear, making it more difficult to exploit in applications \cite{webber12a}. 
A text commonly comprises a sequences of sentences. 
Within a text, the patterns formed by its sentences mean that the whole conveys more than the sum of its separate parts. 
Text structures are the patterns that one sees in multi-sentence texts \cite{webber12a}. 
Recognizing these patterns in terms of the elements that compose them is essential to correctly deriving and interpreting information in the text. 
The elements may be topic, each  about a set entities and what is being said about them.
Texts can be structured by its topics, each comprising a set of entities and a limited range of things being said about them. 
Patterns of coherence relations can also be characteristic of particularly types of text, and therefore be of value in assessing the quality of automatically generated text. 

\section{Evaluation}
\label{sec:coh-eval}

The goal of the research in this thesis is to provide an approach to coherence modeling and compare it with other models. 
To do so, it is essential to have a method to evaluate the performance of coherence models. 
In this section, we complete the definition of the problem, with which the research in this thesis is tackling, by describing the evaluation method we use for assessing the quality of coherence models. 
Other related approaches for evaluating coherence models are discussed in Chapter \ref{ch:rel-work}. 

\subsection{Intrinsic vs. Extrinsic}

Intrinsic and extrinsic are two types of evaluations methodologies \cite{}. 
In an intrinsic evaluation, system output is directly evaluated in terms of a set of norms or predefined criteria about the desired functionality of the system itself. 
In an extrinsic evaluation, system output is assessed in its impact on a task external to the system itself. 

Some research papers on local coherence modeling use intrinsic evaluation approaches such as sentence ordering \cite{karamanis04,barzilay04} (see Chapter \ref{ch:rel-work} for a review of other tasks).  
This evaluation method is primarily designed to model violations of restrictions in centering theory \newcite{karamanis04}. 
The goal is that a coherence model should ideally rank the original order of sentences in a text higher than any permutation of sentences. 

Extrinsic approaches take the coherence of a text as a factor for the quality of the text, given the definition of coherence: What distinguishes a well-written text from others. 
Readability assessment \cite{pitler08} is an example of these approaches. 
In this task, a coherence model is involved with a readability assessment system, which consider other aspect of text quality such as sentence complexity and the like, to evaluate the influence of the coherence model on the end performance of the readability assessment system. 
The insight of this task is that coherent texts are less complex than other ones, therefore they are easy to understand \cite{}. 

In the this thesis we follow extrinsic evaluation methods: the readability assessment task (see experiments in Chapter \ref{ch:coh-patterns} and Chapter \ref{ch:lex-graph}), and the automatic text summarization task \ref{ch:coh-patterns}. 

\subsection{Ranking as Classification} 

Coherence is not a binary property of a text that either exists or not. 
Rather it is a comparative attribute of texts, whether a text is more coherent than the other one. 
For humans it can be ambiguous to decide is a text is coherent or not, but they can rank texts with respect to the coherence property of texts \cite{halliday76}.   

The core of the evaluation method in this thesis is a pairwise ranking task: Given a pair of texts, which one is more coherent. 
Rankings predicted by a coherence model is compared with rankings gathered from human judges. 


\subsection{}









